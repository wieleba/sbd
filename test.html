<html>
<head>
    <meta charset="utf-8"/>
    <link rel="stylesheet" href="style.css"/>
    <link rel="stylesheet" href="style2.css"/>
</head>
<body>
<div class="page">
    <div id="sbo-rt-content">
        <figure data-type="cover">
            <img alt="cover" height="1574" src="test/library/view/optimizing-java/9781492039259/assets/cover.png"
                 width="1200"/>
        </figure>
    </div>
</div>
<div class="page">
    <div id="sbo-rt-content">
        <section data-pdf-bookmark="Optimizing Java" data-type="titlepage" epub:type="titlepage">
            <div class="preface" id="idm139848332082752">
                <h1>
                    Optimizing Java
                </h1>
                <p data-type="subtitle" epub:type="subtitle">
                    Practical Techniques for Improving JVM Application Performance
                </p>
                <p class="author">
                    Benjamin J. Evans, James Gough, and Chris Newland
                </p>
            </div>
        </section>
    </div>
</div>
<div class="page">
    <div id="sbo-rt-content">
        <section data-pdf-bookmark="Optimizing Java" data-type="copyright-page" epub:type="copyright-page">
            <div class="preface" id="idm139848332006928">
                <h1>
                    Optimizing Java
                </h1>
                <p class="author">
                    by
                    <span class="firstname">
     Benjamin
    </span>
                    <span class="othername mi">
     J.
    </span>
                    <span class="surname">
     Evans
    </span>
                    ,
                    <span class="firstname">
     James
    </span>
                    <span class="surname">
     Gough
    </span>
                    , and
                    <span class="firstname">
     Chris
    </span>
                    <span class="surname">
     Newland
    </span>
                </p>
                <p class="copyright">
                    Copyright © 2018 Benjamin J. Evans, James Gough, and Chris Newland. All rights reserved.
                </p>
                <p class="printlocation">
                    Printed in the United States of America.
                </p>
                <p class="publisher">
                    Published by
                    <span class="publishername">
     O’Reilly Media, Inc.
    </span>
                    , 1005 Gravenstein Highway North, Sebastopol, CA 95472.
                </p>
                <p>
                    O’Reilly books may be purchased for educational, business, or sales
                    promotional use. Online editions are also available for most titles (
                    <a href="http://oreilly.com/safari">
                        http://oreilly.com/safari
                    </a>
                    ). For more information, contact our corporate/institutional sales
                    department: 800-998-9938 or
                    <span data-type="email">
     <em>
      corporate@oreilly.com
     </em>
    </span>
                    .
                </p>
                <ul class="stafflist">
                    <li>
     <span class="staffrole">
      Editors:
     </span>
                        Susan Conant and Virginia Wilson
                    </li>
                    <li>
     <span class="staffrole">
      Production Editor:
     </span>
                        Colleen Cole
                    </li>
                    <li>
     <span class="staffrole">
      Copyeditor:
     </span>
                        Rachel Monaghan
                    </li>
                    <li>
     <span class="staffrole">
      Proofreader:
     </span>
                        Rachel Head
                    </li>
                    <li>
     <span class="staffrole">
      Indexer:
     </span>
                        Ellen Troutman-Zaig
                    </li>
                    <li>
     <span class="staffrole">
      Interior Designer:
     </span>
                        David Futato
                    </li>
                    <li>
     <span class="staffrole">
      Cover Designer:
     </span>
                        Randy Comer
                    </li>
                    <li>
     <span class="staffrole">
      Illustrator:
     </span>
                        Anna Evans
                    </li>
                    <li>
     <span class="staffrole">
      Technical Reviewers:
     </span>
                        Julian Templeman, Michael Hsu, Alex Blewitt, Dmitry Vyazelenko
                    </li>
                </ul>
                <ul class="printings">
                    <li>
     <span class="printedition">
      May 2018:
     </span>
                        First Edition
                    </li>
                </ul>
                <!--Add additional revdate spans below as needed.-->
                <div>
                    <h1 class="revisions">
                        Revision History for the First Edition
                    </h1>
                    <ul class="releases">
                        <li>
      <span class="revdate">
       2018-04-12:
      </span>
                            First Release
                        </li>
                    </ul>
                </div>
                <p class="errata">
                    See
                    <a href="http://oreilly.com/catalog/errata.csp?isbn=9781492025795">
                        http://oreilly.com/catalog/errata.csp?isbn=9781492025795
                    </a>
                    for release details.
                </p>
                <div class="legal">
                    <p>
                        The O’Reilly logo is a registered trademark of O’Reilly Media, Inc.
                        <em>
                            Optimizing Java
                        </em>
                        , the cover image, and related trade dress are trademarks
                        of O’Reilly Media, Inc.
                    </p>
                    <p>
                        While the publisher and the authors have used good faith efforts to
                        ensure that the information and instructions contained in this work are
                        accurate, the publisher and the authors disclaim all responsibility for
                        errors or omissions, including without limitation responsibility for
                        damages resulting from the use of or reliance on this work. Use of the
                        information and instructions contained in this work is at your own risk.
                        If any code samples or other technology this work contains or describes is
                        subject to open source licenses or the intellectual property rights of
                        others, it is your responsibility to ensure that your use thereof complies
                        with such licenses and/or rights.
                        <!--PROD: Uncomment the following sentence if appropriate and add it to the
        above para:-->
                        <!--This book is not intended as [legal/medical/financial; use the appropriate
        reference] advice. Please consult a qualified professional if you
        require [legal/medical/financial] advice.-->
                    </p>
                </div>
                <div class="copyright-bottom">
                    <p class="isbn">
                        978-1-492-02579-5
                    </p>
                    <p class="printer">
                        [LSI]
                    </p>
                </div>
            </div>
        </section>
    </div>
</div>
<div class="page">
    <div id="sbo-rt-content">
        <section data-pdf-bookmark="Dedication" data-type="dedication" epub:type="dedication">
            <div class="dedication" id="idm139848325935344">
                <h1>
                    Dedication
                </h1>
                <p>
                    This book is dedicated to my wife, Anna, who not only illustrated it beautifully, but also helped
                    edit portions and, crucially, was often the first person I bounced ideas off.
                </p>
                <p data-type="attribution">
                    —Benjamin J. Evans
                </p>
                <br/>
                <br/>
                <br/>
                <p>
                    This book is dedicated to my incredible family Megan, Emily, and Anna. Writing would not have been
                    possible without their help and support. I’d also like to thank my parents, Heather and Paul, for
                    encouraging me to learn and their constant support.
                </p>
                <p>
                    I’d also like to thank Benjamin Evans for his guidance and friendship—it’s been a pleasure working
                    together again.
                </p>
                <p data-type="attribution">
                    —James Gough
                </p>
                <br/>
                <br/>
                <br/>
                <p>
                    This book is dedicated to my wife, Reena, who supported and encouraged my efforts and to my sons,
                    Joshua and Hugo, may they grow up with inquisitive minds.
                </p>
                <p data-type="attribution">
                    —Chris Newland
                </p>
            </div>
        </section>
    </div>
</div>
<div class="page">
    <div id="sbo-rt-content">
        <section data-pdf-bookmark="Foreword" data-type="foreword" epub:type="foreword">
            <div class="preface" id="idm139848332101072">
                <h1>
                    Foreword
                </h1>
                <p>
                    How do you define performance?
                </p>
                <p>
                    Most developers, when asked about the performance of their application, will assume some measure of
                    speed is requested. Something like transactions per second, or gigabytes of data processed…getting a
                    lot of work done in the shortest amount of time possible. If you’re an application architect, you
                    may measure performance in broader metrics. You may be more concerned about resource utilization
                    than straight-line execution. You might pay more attention to the performance of connections between
                    services than of the services themselves. If you make business decisions for your company,
                    application performance will probably not be measured in time as often as it is measured in dollars.
                    You may argue with developers and architects about resource allocation, weighing the cost of devops
                    against the time it takes to do the company’s work.
                </p>
                <p>
                    And regardless of which role you identify with, all these metrics are important.
                </p>
                <p>
                    I started out developing Java applications in 1996. I had just moved from my first job writing
                    AppleScript CGIs for the University of Minnesota’s business school to maintaining server-side Perl
                    applications for the web development team. Java was very new then—the first stable version, 1.0.2,
                    was released earlier that year—and I was tasked with finding something useful to build.
                </p>
                <p>
                    Back in those days, the best way to get performance out of a Java application was to write it in
                    some other language. This was before Java had a Just-in-Time (JIT) compiler, before parallel and
                    concurrent garbage collectors, and long before the server side would become dominated by Java
                    technology. But many of us wanted to use Java, and we developed all sorts of tricks to make our code
                    run well. We wrote gigantic methods to avoid method dispatch overhead. We pooled and reused objects
                    because garbage collection was slow and disruptive. We used lots of global state and static methods.
                    We wrote truly awful Java code, but it worked…for a little while.
                </p>
                <p>
                    In 1999, things started to change.
                </p>
                <p>
                    After years struggling to use Java for anything demanding speed, JIT technologies started to reach
                    us. With compilers that could inline methods, the number of method calls became less important than
                    breaking up our giant monoliths into smaller pieces. We gleefully embraced object-oriented design,
                    splitting our methods into tiny chunks and wrapping interfaces around everything. We marveled at how
                    every release of Java would run things just a little bit better, because we were writing good Java
                    code and the JIT compiler loved it. Java soared past other technologies on the server, leading us to
                    build larger and more complex apps with richer abstractions.
                </p>
                <p>
                    At the same time, garbage collectors were rapidly improving. Now the overhead of pooling would very
                    frequently overshadow the cost of allocation. Many garbage collectors offered multithreaded
                    operation, and we started to see low-pause, nearly concurrent GCs that stayed out of our
                    applications’ way. The standard practice moved toward a carefree creating and throwing away of
                    objects with the promise that a sufficiently smart GC would eventually make it all OK. And it
                    worked…for a little while.
                </p>
                <p>
                    The problem with technology is that it always invalidates itself. As JIT and GC technologies have
                    improved, the paths to application performance have become tricky to navigate. Even though JVMs can
                    optimize our code and make objects almost free, the demands of applications and users continue to
                    grow.
                </p>
                <p>
                    Some of the time, maybe even most of the time, the “good” coding patterns prevail: small methods
                    inline properly, interface and type checks become inexpensive, native code produced by the JIT
                    compiler is compact and efficient. But other times we need to hand-craft our code, dial back
                    abstractions and architecture in deference to the limitations of the compiler and CPU. Some of the
                    time, objects really are free and we can ignore the fact that we’re consuming memory bandwidth and
                    GC cycles. Other times we’re dealing with terabyte-scale (or larger) datasets that put stress on
                    even the best garbage collectors and memory subsystems.
                </p>
                <p>
                    The answer to the performance question these days is to know your tools. And frequently, that means
                    knowing not just how Java the language works, but also how JVM libraries, memory, the compiler, GCs,
                    and the hardware your apps run on are interacting. In my work on the JRuby project, I’ve learned an
                    immutable truth about the JVM: there’s no single solution for all performance problems, but for all
                    performance problems there are solutions. The trick is finding those solutions and piecing together
                    the ones that meet your needs best. Now you have a secret weapon in these performance battles: the
                    book you are about to read.
                </p>
                <p>
                    Turn the page, friends, and discover the wealth of tools and techniques available to you. Learn how
                    to balance application design with available resources. Learn how to monitor and tune the JVM. Learn
                    how to make use of the latest Java technologies that are more efficient than old libraries and
                    patterns. Learn how to make Java fly.
                </p>
                <p>
                    It’s an exciting time to be a Java developer, and there have never been so many opportunities to
                    build efficient and responsive applications on the Java platform. Let’s get started.
                </p>
                <p class="byline">
                    Charlie Nutter
                </p>
                <p class="byline cont">
                    Principal Software Engineer,
                </p>
                <p class="byline cont">
                    Red Hat Middleware
                </p>
            </div>
        </section>
    </div>
</div>
<div class="page">
    <div id="sbo-rt-content">
        <section data-pdf-bookmark="Preface" data-type="preface" epub:type="preface">
            <div class="preface" id="pracjavaperf-PREF">
                <h1>
                    Preface
                </h1>
                <section data-pdf-bookmark="Conventions Used in This Book" data-type="sect1">
                    <div class="sect1" id="idm139848331939328">
                        <h1>
                            Conventions Used in This Book
                        </h1>
                        <p>
                            The following typographical conventions are used in this book:
                        </p>
                        <dl>
                            <dt>
                                <em>
                                    Italic
                                </em>
                            </dt>
                            <dd>
                                <p>
                                    Indicates new terms, URLs, email addresses, filenames, and file extensions.
                                </p>
                            </dd>
                            <dt>
                                <code>
                                    Constant width
                                </code>
                            </dt>
                            <dd>
                                <p>
                                    Used for program listings, as well as within paragraphs to refer to program elements
                                    such as variable or function names, databases, data types, environment variables,
                                    statements, and keywords.
                                </p>
                            </dd>
                            <dt>
                                <code>
                                    &lt;constant width&gt;
                                </code>
                                in angle brackets
                            </dt>
                            <dd>
                                <p>
                                    Shows text that should be replaced with user-supplied values or by values determined
                                    by context.
                                </p>
                            </dd>
                        </dl>
                        <div data-type="tip">
                            <h6>
                                Tip
                            </h6>
                            <p>
                                This element signifies a tip or suggestion.
                            </p>
                        </div>
                        <div data-type="note" epub:type="note">
                            <h6>
                                Note
                            </h6>
                            <p>
                                This element signifies a general note.
                            </p>
                        </div>
                        <div data-type="warning" epub:type="warning">
                            <h6>
                                Warning
                            </h6>
                            <p>
                                This element indicates a warning or caution.
                            </p>
                        </div>
                    </div>
                </section>
                <section data-pdf-bookmark="Using Code Examples" data-type="sect1">
                    <div class="sect1" id="idm139848332030864">
                        <h1>
                            Using Code Examples
                        </h1>
                        <!--PROD: Please reach out to author to find out if they will be uploading code examples to oreilly.com or their own site (e.g., GitHub). If there is no code download, delete this whole section. If there is, when you email digidist with the link, let them know what you filled in for title_title (should be as close to book title as possible, i.e., learning_python_2e). This info will determine where digidist loads the files.-->
                        <p>
                            Supplemental material (code examples, exercises, etc.) is available for download at
                            <a href="http://bit.ly/optimizing-java-1e-code-examples">
                                <em class="hyperlink">
                                    http://bit.ly/optimizing-java-1e-code-examples
                                </em>
                            </a>
                            .
                        </p>
                        <p>
                            This book is here to help you get your job done. In general, if example code is offered with
                            this book, you may use it in your programs and documentation. You do not need to contact us
                            for permission unless you’re reproducing a significant portion of the code. For example,
                            writing a program that uses several chunks of code from this book does not require
                            permission. Selling or distributing a CD-ROM of examples from O’Reilly books does require
                            permission. Answering a question by citing this book and quoting example code does not
                            require permission. Incorporating a significant amount of example code from this book into
                            your product’s documentation does require permission.
                        </p>
                        <p>
                            We appreciate, but do not require, attribution. An attribution usually includes the title,
                            author, publisher, and ISBN. For example: “
                            <em>
                                Optimizing Java
                            </em>
                            by Benjamin J. Evans, James Gough, and Chris Newland (O’Reilly). Copyright 2018 Benjamin J.
                            Evans, James Gough, and Chris Newland, 978-1-492-02579-5.”
                        </p>
                        <p>
                            If you feel your use of code examples falls outside fair use or the permission given above,
                            feel free to contact us at
                            <a class="email" href="mailto:permissions@oreilly.com">
                                <em>
                                    permissions@oreilly.com
                                </em>
                            </a>
                            .
                        </p>
                    </div>
                </section>
                <section data-pdf-bookmark="O’Reilly Safari" data-type="sect1">
                    <div class="sect1" id="idm139848332013264">
                        <h1>
                            O’Reilly Safari
                        </h1>
                        <div class="safarienabled" data-type="note" epub:type="note">
                            <h6>
                                Note
                            </h6>
                            <p>
                                <a class="orm:hideurl" href="http://oreilly.com/safari">
                                    <em class="hyperlink">
                                        Safari
                                    </em>
                                </a>
                                (formerly Safari Books Online) is a membership-based training and reference platform for
                                enterprise, government, educators, and individuals.
                            </p>
                        </div>
                        <p>
                            Members have access to thousands of books, training videos, Learning Paths, interactive
                            tutorials, and curated playlists from over 250 publishers, including O’Reilly Media, Harvard
                            Business Review, Prentice Hall Professional, Addison-Wesley Professional, Microsoft Press,
                            Sams, Que, Peachpit Press, Adobe, Focal Press, Cisco Press, John Wiley &amp; Sons, Syngress,
                            Morgan Kaufmann, IBM Redbooks, Packt, Adobe Press, FT Press, Apress, Manning, New Riders,
                            McGraw-Hill, Jones &amp; Bartlett, and Course Technology, among others.
                        </p>
                        <p>
                            For more information, please visit
                            <a class="orm:hideurl" href="http://oreilly.com/safari">
                                <em>
                                    http://oreilly.com/safari
                                </em>
                            </a>
                            .
                        </p>
                    </div>
                </section>
                <section class="pagebreak-before less_space" data-pdf-bookmark="How to Contact Us" data-type="sect1">
                    <div class="sect1" id="idm139848331681104">
                        <h1>
                            How to Contact Us
                        </h1>
                        <p>
                            Please address comments and questions concerning this book to the publisher:
                        </p>
                        <ul class="simplelist">
                            <li>
                                O’Reilly Media, Inc.
                            </li>
                            <li>
                                1005 Gravenstein Highway North
                            </li>
                            <li>
                                Sebastopol, CA 95472
                            </li>
                            <li>
                                800-998-9938 (in the United States or Canada)
                            </li>
                            <li>
                                707-829-0515 (international or local)
                            </li>
                            <li>
                                707-829-0104 (fax)
                            </li>
                        </ul>
                        <p>
                            We have a web page for this book, where we list errata, examples, and any additional
                            information. You can access this page at
                            <a href="http://bit.ly/optimizing-java">
                                <em class="hyperlink">
                                    http://bit.ly/optimizing-java
                                </em>
                            </a>
                            .
                        </p>
                        <!--Don't forget to update the link above.-->
                        <p>
                            To comment or ask technical questions about this book, send email to
                            <a class="email" href="mailto:bookquestions@oreilly.com">
                                <em>
                                    bookquestions@oreilly.com
                                </em>
                            </a>
                            .
                        </p>
                        <p>
                            For more information about our books, courses, conferences, and news, see our website at
                            <a href="http://www.oreilly.com">
                                <em class="hyperlink">
                                    http://www.oreilly.com
                                </em>
                            </a>
                            .
                        </p>
                        <p>
                            Find us on Facebook:
                            <a href="http://facebook.com/oreilly">
                                <em class="hyperlink">
                                    http://facebook.com/oreilly
                                </em>
                            </a>
                        </p>
                        <p>
                            Follow us on Twitter:
                            <a href="http://twitter.com/oreillymedia">
                                <em class="hyperlink">
                                    http://twitter.com/oreillymedia
                                </em>
                            </a>
                        </p>
                        <p>
                            Watch us on YouTube:
                            <a href="http://www.youtube.com/oreillymedia">
                                <em class="hyperlink">
                                    http://www.youtube.com/oreillymedia
                                </em>
                            </a>
                        </p>
                    </div>
                </section>
                <section data-pdf-bookmark="Acknowledgments" data-type="sect1">
                    <div class="sect1" id="idm139848331680576">
                        <h1>
                            Acknowledgments
                        </h1>
                        <p>
                            The authors would like to thank a large number of people for their
                            invaluable assistance.
                        </p>
                        <p>
                            For writing the foreword:
                        </p>
                        <ul>
                            <li>
                                <p>
                                    Charlie Nutter
                                </p>
                            </li>
                        </ul>
                        <p>
                            For providing highly specialist technical help, including information
                            and knowledge not available anywhere else:
                        </p>
                        <ul>
                            <li>
                                <p>
                                    Christine Flood
                                </p>
                            </li>
                            <li>
                                <p>
                                    Chris Seaton
                                </p>
                            </li>
                            <li>
                                <p>
                                    Kirk Pepperdine
                                </p>
                            </li>
                            <li>
                                <p>
                                    Simon Ritter
                                </p>
                            </li>
                            <li>
                                <p>
                                    Monica Beckwith
                                </p>
                            </li>
                            <li>
                                <p>
                                    David Jones
                                </p>
                            </li>
                            <li>
                                <p>
                                    Richard Warburton
                                </p>
                            </li>
                            <li>
                                <p>
                                    Stephen Connolly
                                </p>
                            </li>
                            <li>
                                <p>
                                    Jaroslav Tulach
                                </p>
                            </li>
                        </ul>
                        <p>
                            For general detail, encouragement, advice and introductions:
                        </p>
                        <ul>
                            <li>
                                <p>
                                    George Ball
                                </p>
                            </li>
                            <li>
                                <p>
                                    Steve Poole
                                </p>
                            </li>
                            <li>
                                <p>
                                    Richard Pollock
                                </p>
                            </li>
                            <li>
                                <p>
                                    Andrew Binstock
                                </p>
                            </li>
                        </ul>
                        <p>
                            Our technical reviewers:
                        </p>
                        <ul>
                            <li>
                                <p>
                                    Michael Hsu
                                </p>
                            </li>
                            <li>
                                <p>
                                    Dmitry Vyazelenko
                                </p>
                            </li>
                            <li>
                                <p>
                                    Julian Templeman
                                </p>
                            </li>
                            <li>
                                <p>
                                    Alex Blewitt
                                </p>
                            </li>
                        </ul>
                        <p>
                            The O’Reilly Team:
                        </p>
                        <ul>
                            <li>
                                <p>
                                    Virginia Wilson
                                </p>
                            </li>
                            <li>
                                <p>
                                    Susan Conant
                                </p>
                            </li>
                            <li>
                                <p>
                                    Colleen Cole
                                </p>
                            </li>
                            <li>
                                <p>
                                    Rachel Monaghan
                                </p>
                            </li>
                            <li>
                                <p>
                                    Nan Barber
                                </p>
                            </li>
                            <li>
                                <p>
                                    Brian Foster
                                </p>
                            </li>
                            <li>
                                <p>
                                    Lindsay Ventimiglia
                                </p>
                            </li>
                            <li>
                                <p>
                                    Maureen Spencer
                                </p>
                            </li>
                            <li>
                                <p>
                                    Heather Scherer
                                </p>
                            </li>
                        </ul>
                    </div>
                </section>
            </div>
        </section>
    </div>
</div>
<div class="page">
    <div id="sbo-rt-content">
        <section class="pagenumrestart" data-pdf-bookmark="Chapter 1. Optimization and Performance Defined"
                 data-type="chapter" epub:type="chapter">
            <div class="chapter" id="pracjavaperf-CHP-1">
                <h1>
    <span class="label">
     Chapter 1.
    </span>
                    Optimization and Performance Defined
                </h1>
                <p>
                    Optimizing the performance of Java (or any other sort of code) is often seen as a Dark Art.
                    <a data-primary="performance" data-type="indexterm" id="ix_perf1">
                    </a>
                    There’s a mystique about performance analysis—it’s commonly viewed as a craft practiced by the “lone
                    hacker, who is tortured and deep thinking” (one of Hollywood’s favorite tropes about computers and
                    the people who operate them).
                    The image is one of a single individual who can see deeply into a system and come up with a magic
                    solution that makes the system work faster.
                    <a data-primary="performance optimizations" data-seealso="performance" data-type="indexterm"
                       id="idm139848331880512">
                    </a>
                </p>
                <p>
                    This image is often coupled with the unfortunate (but all-too-common) situation where performance is
                    a second-class concern of the software teams.
                    This sets up a scenario where analysis is only done once the system is already in trouble, and so
                    needs a performance “hero” to save it.
                    The reality, however, is a little different.
                </p>
                <p>
                    The truth is that performance analysis is a weird blend of hard empiricism and squishy human
                    psychology.
                    What matters is, at one and the same time, the absolute numbers of observable metrics and how the
                    end users and stakeholders
                    <em>
                        feel
                    </em>
                    about them.
                    The resolution of this apparent paradox is the subject of the rest of this book.
                </p>
                <section data-pdf-bookmark="Java Performance—The Wrong Way" data-type="sect1">
                    <div class="sect1" id="pracjavaperf-CHP-1-SECT-1">
                        <h1>
                            Java Performance—The Wrong Way
                        </h1>
                        <p>
                            For many years, one of the top three hits on Google for “Java performance tuning” was an
                            article from 1997–8, which had been ingested into the index very early in Google’s history.
                            <a data-primary="performance" data-secondary="misconceptions about Java performance"
                               data-type="indexterm" id="idm139848331875312">
                            </a>
                            The page had presumably stayed close to the top because its initial ranking served to
                            actively drive traffic to it, creating a feedback loop.
                        </p>
                        <p>
                            The page housed advice that was completely out of date, no longer true, and in many cases
                            detrimental to applications.
                            However, its favored position in the search engine results caused many, many developers to
                            be exposed to terrible advice.
                        </p>
                        <p>
                            For example, very early versions of Java had terrible method dispatch performance.
                            As a workaround, some Java developers advocated avoiding writing small methods and instead
                            writing monolithic methods.
                            Of course, over time, the performance of virtual dispatch greatly improved. Not only that,
                            but with modern Java Virtual Machines (JVMs) and especially automatic managed inlining,
                            virtual dispatch has now been eliminated at the majority of call sites.
                            <a data-primary="Java Virtual Machines" data-see="JVMs" data-type="indexterm"
                               id="idm139848331872464">
                            </a>
                            Code that followed the “lump everything into one method” advice is now at a substantial
                            disadvantage, as it is very unfriendly to modern Just-in-Time (JIT) compilers.
                        </p>
                        <p>
                            There’s no way of knowing how much damage was done to the performance of applications that
                            were subjected to the bad advice, but this case neatly demonstrates the dangers of not using
                            a quantitative and verifiable approach to performance. It also provides another excellent
                            example of why you shouldn’t believe everything you read
                            on the internet.
                        </p>
                        <div data-type="note" epub:type="note">
                            <h6>
                                Note
                            </h6>
                            <p>
                                The execution speed of Java code is highly dynamic and fundamentally depends on the
                                underlying Java Virtual Machine.
                                <a data-primary="JVMs (Java Virtual Machines)"
                                   data-secondary="execution speed of code and" data-type="indexterm"
                                   id="idm139848331797824">
                                </a>
                                An old piece of Java code may well execute faster on a more recent JVM, even without
                                recompiling the Java source code.
                            </p>
                        </div>
                        <p>
                            As you might imagine, for this reason (and others we will discuss later) this book is not a
                            cookbook of performance tips to apply to your code. Instead, we focus on a range of aspects
                            that come together to produce good performance engineering:
                        </p>
                        <ul>
                            <li>
                                <p>
                                    Performance methodology within the overall software lifecycle
                                </p>
                            </li>
                            <li>
                                <p>
                                    Theory of testing as applied to performance
                                </p>
                            </li>
                            <li>
                                <p>
                                    Measurement, statistics, and tooling
                                </p>
                            </li>
                            <li>
                                <p>
                                    Analysis skills (both systems and data)
                                </p>
                            </li>
                            <li>
                                <p>
                                    Underlying technology and mechanisms
                                </p>
                            </li>
                        </ul>
                        <p>
                            Later in the book, we will introduce some heuristics and code-level techniques for
                            optimization, but these all come with caveats and tradeoffs that the developer should be
                            aware of before using them.
                        </p>
                        <div data-type="tip">
                            <h6>
                                Tip
                            </h6>
                            <p>
                                Please do not skip ahead to those sections and start applying the techniques detailed
                                without properly understanding the context in which the advice is given.
                                All of these techniques are capable of doing more harm than good if you lack a proper
                                understanding of how they should be applied.
                            </p>
                        </div>
                        <p class="pagebreak-before">
                            In general, there are:
                        </p>
                        <ul>
                            <li>
                                <p>
                                    No magic “go faster” switches for the JVM
                                </p>
                            </li>
                            <li>
                                <p>
                                    No “tips and tricks” to make Java run faster
                                </p>
                            </li>
                            <li>
                                <p>
                                    No secret algorithms that have been hidden from you
                                </p>
                            </li>
                        </ul>
                        <p>
                            As we explore our subject, we will discuss these misconceptions in more detail, along with
                            some other common mistakes that developers often make when approaching Java performance
                            analysis and related issues. Still here? Good. Then let’s talk about performance.
                        </p>
                    </div>
                </section>
                <section data-pdf-bookmark="Java Performance Overview" data-type="sect1">
                    <div class="sect1" id="pracjavaperf-CHP-1-SECT-2">
                        <h1>
                            Java Performance Overview
                        </h1>
                        <p>
                            To understand why Java performance is the way that it is, let’s start by considering a
                            classic quote from James Gosling,
                            <a data-primary="performance" data-secondary="overview of Java performance"
                               data-type="indexterm" id="idm139848331782176">
                            </a>
                            the creator of Java:
                        </p>
                        <blockquote>
                            <p>
                                Java is a blue collar language. It’s not PhD thesis material but a language for a job.
                            </p>
                        </blockquote>
                        <p>
                            That is, Java has always been an extremely practical language. Its attitude to performance
                            was initially that as long as the environment was
                            <em>
                                fast enough
                            </em>
                            , then raw performance could be sacrificed if developer productivity benefited. It was
                            therefore not until relatively recently, with the increasing maturity and sophistication of
                            JVMs such as HotSpot, that the Java environment became suitable for high-performance
                            computing applications.
                            <a data-primary="HotSpot JVM" data-type="indexterm" id="idm139848331778896">
                            </a>
                        </p>
                        <p>
                            This practicality manifests itself in many ways in the Java platform, but one of the most
                            obvious is the used of
                            <em>
                                managed subsystems
                            </em>
                            .
                            <a data-primary="managed subsystems" data-type="indexterm" id="idm139848331777264">
                            </a>
                            The idea is that the developer gives up some aspects of low-level control in exchange for
                            not having to worry about some of the details of the capability under management.
                        </p>
                        <p>
                            The most obvious example of this is, of course, memory management.
                            <a data-primary="memory management" data-type="indexterm" id="idm139848331588864">
                            </a>
                            The JVM provides automatic memory management in the form of a pluggable garbage collection
                            subsystem, so that memory does not have to be manually tracked by the programmer.
                        </p>
                        <div data-type="note" epub:type="note">
                            <h6>
                                Note
                            </h6>
                            <p>
                                Managed subsystems occur throughout the JVM and their existence introduces extra
                                complexity into the runtime behavior of JVM applications.
                            </p>
                        </div>
                        <p>
                            As we will discuss in the next section, the complex runtime behavior of JVM applications
                            requires us to treat our applications as experiments under test.
                            This leads us to think about the statistics of observed measurements, and here we make an
                            unfortunate discovery.
                        </p>
                        <p>
                            The observed performance measurements of JVM applications are very often not normally
                            distributed.
                            <a data-primary="statistics"
                               data-secondary="naive techniques, inappropriate use for Java/JVM performance"
                               data-type="indexterm" id="idm139848331585264">
                            </a>
                            This means that elementary statistical techniques (e.g.,
                            <em>
                                standard deviation
                            </em>
                            and
                            <em>
                                variance
                            </em>
                            ) are ill-suited for handling results from JVM applications.
                            This is because many basic statistics methods contain an implicit assumption about the
                            normality of results distributions.
                        </p>
                        <p>
                            One way to understand this is that for JVM applications outliers can be very significant—for
                            a low-latency trading application, for example.
                            This means that sampling of measurements is also problematic, as it can easily miss the
                            exact events that have the most importance.
                        </p>
                        <p>
                            Finally, a word of caution.
                            It is very easy to be misled by Java performance measurements.
                            The complexity of the environment means that it is very hard to isolate individual aspects
                            of the system.
                        </p>
                        <p>
                            Measurement also has an overhead, and frequent sampling (or recording every result) can have
                            an observable impact on the performance numbers being recorded.
                            The nature of Java performance numbers requires a certain amount of statistical
                            sophistication, and naive techniques frequently produce incorrect results when applied to
                            Java/JVM applications.
                        </p>
                    </div>
                </section>
                <section data-pdf-bookmark="Performance as an Experimental Science" data-type="sect1">
                    <div class="sect1" id="pracjavaperf-CHP-1-SECT-3">
                        <h1>
                            Performance as an Experimental Science
                        </h1>
                        <p>
                            Java/JVM software stacks are, like most modern software systems, very complex.
                            <a data-primary="performance" data-secondary="as experimental science" data-type="indexterm"
                               id="idm139848331579104">
                            </a>
                            In fact, due to the highly optimizing and adaptive nature of the JVM, production systems
                            built on top of the JVM can have some incredibly subtle and intricate performance behavior.
                            This complexity has been made possible by Moore’s Law and the unprecedented growth in
                            hardware capability that it represents.
                        </p>
                        <blockquote>
                            <p>
                                The most amazing achievement of the computer software industry is its continuing
                                cancellation of the steady and staggering gains made by the computer hardware industry.
                            </p>
                            <p data-type="attribution">
                                Henry Petroski
                            </p>
                        </blockquote>
                        <p>
                            While some software systems have squandered the historical gains of the industry, the JVM
                            represents something of an engineering triumph.
                            <a data-primary="JVMs (Java Virtual Machines)" data-secondary="high-performance nature of"
                               data-type="indexterm" id="idm139848331575360">
                            </a>
                            Since its inception in the late 1990s the JVM has developed into a very high-performance,
                            general-purpose execution environment that puts those gains to very good use.
                            The tradeoff, however, is that like any complex, high-performance system, the JVM requires a
                            measure of skill and experience to get the absolute best out of it.
                        </p>
                        <blockquote>
                            <p>
                                A measurement not clearly defined is worse than useless.
                            </p>
                            <p data-type="attribution">
                                Eli Goldratt
                            </p>
                        </blockquote>
                        <p>
                            JVM performance tuning is therefore a synthesis between technology, methodology, measurable
                            quantities, and tools.
                            <a data-primary="JVMs (Java Virtual Machines)"
                               data-secondary="performance tuning, experimental nature of" data-type="indexterm"
                               id="idm139848331571648">
                            </a>
                            Its aim is to effect measurable outputs in a manner desired by the owners or users of a
                            system.
                            In other words, performance is an experimental science—it achieves a desired result by:
                        </p>
                        <ul>
                            <li>
                                <p>
                                    Defining the desired outcome
                                </p>
                            </li>
                            <li>
                                <p>
                                    Measuring the existing system
                                </p>
                            </li>
                            <li>
                                <p>
                                    Determining what is to be done to achieve the requirement
                                </p>
                            </li>
                            <li>
                                <p>
                                    Undertaking an improvement exercise
                                </p>
                            </li>
                            <li>
                                <p>
                                    Retesting
                                </p>
                            </li>
                            <li>
                                <p>
                                    Determining whether the goal has been achieved
                                </p>
                            </li>
                        </ul>
                        <p>
                            The process of defining and determining desired performance outcomes builds a set of
                            quantitative objectives.
                            It is important to establish what should be measured and record the objectives, which then
                            form part of the project’s artifacts and deliverables.
                            From this, we can see that performance analysis is based upon defining, and then achieving,
                            nonfunctional requirements.
                        </p>
                        <p>
                            This process is, as has been previewed, not one of reading chicken entrails or another
                            divination method.
                            Instead, we rely upon statistics and an appropriate handling of results.
                            In
                            <a data-type="xref" href="ch05.html#pracjavaperf-CHP-5">
                                Chapter 5
                            </a>
                            we will introduce a primer on the basic statistical techniques that are required for
                            accurate handling of data generated from a JVM performance analysis project.
                        </p>
                        <p>
                            For many real-world projects, a more sophisticated understanding of data and statistics will
                            undoubtedly be required.
                            You are encouraged to view the statistical techniques found in this book as a starting
                            point, rather than a definitive statement.
                        </p>
                    </div>
                </section>
                <section data-pdf-bookmark="A Taxonomy for Performance" data-type="sect1">
                    <div class="sect1" id="pracjavaperf-CHP-1-SECT-4">
                        <h1>
                            A Taxonomy for Performance
                        </h1>
                        <p>
                            In this section, we introduce some basic performance metrics.
                            <a data-primary="performance" data-secondary="taxonomy for" data-type="indexterm"
                               id="ix_perf1tax">
                            </a>
                            These provide a vocabulary for performance analysis and will allow you to frame the
                            objectives of a tuning project in quantitative terms.
                            These objectives are the nonfunctional requirements that define performance goals.
                            One common basic set of performance
                            <span class="keep-together">
       metrics is:
      </span>
                        </p>
                        <ul>
                            <li>
                                <p>
                                    Throughput
                                </p>
                            </li>
                            <li>
                                <p>
                                    Latency
                                </p>
                            </li>
                            <li>
                                <p>
                                    Capacity
                                </p>
                            </li>
                            <li>
                                <p>
                                    Utilization
                                </p>
                            </li>
                            <li>
                                <p>
                                    Efficiency
                                </p>
                            </li>
                            <li>
                                <p>
                                    Scalability
                                </p>
                            </li>
                            <li>
                                <p>
                                    Degradation
                                </p>
                            </li>
                        </ul>
                        <p>
                            We will briefly discuss each in turn.
                            Note that for most performance projects, not every metric will be optimized simultaneously.
                            The case of only a few metrics being improved in a single performance iteration is far more
                            common, and this may be as many as can be tuned at once.
                            In real-world projects, it may well be the case that optimizing one metric comes at the
                            detriment of another metric or group of metrics.
                        </p>
                        <section data-pdf-bookmark="Throughput" data-type="sect2">
                            <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.1">
                                <h2>
                                    Throughput
                                </h2>
                                <p>
                                    Throughput is a metric that represents the rate of work a system or subsystem can
                                    perform.
                                    <a data-primary="performance metrics" data-secondary="throughput"
                                       data-type="indexterm" id="idm139848332127824">
                                    </a>
                                    <a data-primary="throughput" data-secondary="about" data-type="indexterm"
                                       id="idm139848332126848">
                                    </a>
                                    This is usually expressed as number of units of work in some time period.
                                    For example, we might be interested in how many transactions per second a system can
                                    execute.
                                </p>
                                <p>
                                    For the throughput number to be meaningful in a real performance exercise, it should
                                    include a description of the reference platform it was obtained on.
                                    For example, the hardware spec, OS, and software stack are all relevant to
                                    throughput, as is whether the system under test is a single server or a cluster.
                                    In addition, transactions (or units of work) should be the same between tests.
                                    Essentially, we should seek to ensure that the workload for throughput tests is kept
                                    consistent between runs.
                                </p>
                            </div>
                        </section>
                        <section data-pdf-bookmark="Latency" data-type="sect2">
                            <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.2">
                                <h2>
                                    Latency
                                </h2>
                                <p>
                                    Performance metrics are sometimes explained via metaphors that evoke plumbing.
                                    If a water pipe can produce 100 liters per second, then the volume produced in 1
                                    second (100 liters) is the throughput.
                                    <a data-primary="latency" data-secondary="about" data-type="indexterm"
                                       id="idm139848332122608">
                                    </a>
                                    <a data-primary="performance metrics" data-secondary="latency" data-type="indexterm"
                                       id="idm139848332121632">
                                    </a>
                                    In this metaphor, the latency is effectively the length of the pipe.
                                    That is, it’s the time taken to process a single transaction and see a result at the
                                    other end of the pipe.
                                </p>
                                <p>
                                    It is normally quoted as an end-to-end time.
                                    It is dependent on workload, so a common approach is to produce a graph showing
                                    latency as a function of increasing workload.
                                    We will see an example of this type of graph in
                                    <a data-type="xref" href="#pracjavaperf-CHP-1-SECT-5">
                                        “Reading Performance Graphs”
                                    </a>
                                    .
                                </p>
                            </div>
                        </section>
                        <section data-pdf-bookmark="Capacity" data-type="sect2">
                            <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.3">
                                <h2>
                                    Capacity
                                </h2>
                                <p>
                                    The capacity is the amount of work parallelism a system possesses—that is, the
                                    number of units of work (e.g., transactions) that can be simultaneously ongoing in
                                    the
                                    system.
                                    <a data-primary="performance metrics" data-secondary="capacity"
                                       data-type="indexterm" id="idm139848332116832">
                                    </a>
                                    <a data-primary="capacity" data-type="indexterm" id="idm139848332115856">
                                    </a>
                                </p>
                                <p>
                                    Capacity is obviously related to throughput, and we should expect that as the
                                    concurrent load on a system increases, throughput (and latency) will be
                                    affected. For this reason, capacity is usually quoted as the processing available at
                                    a given value of latency or throughput.
                                </p>
                            </div>
                        </section>
                        <section data-pdf-bookmark="Utilization" data-type="sect2">
                            <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.4">
                                <h2>
                                    Utilization
                                </h2>
                                <p>
                                    One of the most common performance analysis tasks is to achieve efficient use of a
                                    system’s resources.
                                    <a data-primary="CPU utilization" data-type="indexterm" id="idm139848332112512">
                                    </a>
                                    Ideally, CPUs should be used for handling units of work, rather than being idle (or
                                    spending time handling OS or other housekeeping tasks).
                                    <a data-primary="performance metrics" data-secondary="utilization"
                                       data-type="indexterm" id="idm139848332111520">
                                    </a>
                                    <a data-primary="utilization" data-secondary="about" data-type="indexterm"
                                       id="idm139848332110576">
                                    </a>
                                </p>
                                <p>
                                    Depending on the workload, there can be a huge difference between the utilization
                                    levels of different resources. For example, a computation-intensive workload (such
                                    as graphics processing or encryption) may be running at close to 100% CPU but only
                                    be using a small percentage of available memory.
                                </p>
                            </div>
                        </section>
                        <section data-pdf-bookmark="Efficiency" data-type="sect2">
                            <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.5">
                                <h2>
                                    Efficiency
                                </h2>
                                <p>
                                    Dividing the throughput of a system by the utilized resources gives a measure of the
                                    overall efficiency of the system.
                                    <a data-primary="performance metrics" data-secondary="efficiency"
                                       data-type="indexterm" id="idm139848332106928">
                                    </a>
                                    <a data-primary="efficiency" data-type="indexterm" id="idm139848332105952">
                                    </a>
                                    Intuitively, this makes sense, as requiring more resources to produce the same
                                    throughput is one useful definition of being less efficient.
                                </p>
                                <p>
                                    It is also possible, when one is dealing with larger systems, to use a form of cost
                                    accounting to measure efficiency. If solution A has a total dollar cost of ownership
                                    (TCO) twice that of solution B for the same throughput then it is, clearly, half as
                                    efficient.
                                </p>
                            </div>
                        </section>
                        <section data-pdf-bookmark="Scalability" data-type="sect2">
                            <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.6">
                                <h2>
                                    Scalability
                                </h2>
                                <p>
                                    The throughout or capacity of a system depends upon the resources available for
                                    processing.
                                    <a data-primary="scalability" data-secondary="about" data-type="indexterm"
                                       id="idm139848331774176">
                                    </a>
                                    <a data-primary="performance metrics" data-secondary="scalability"
                                       data-type="indexterm" id="idm139848331773200">
                                    </a>
                                    The change in throughput as resources are added is one measure of the scalability of
                                    a system or application. The holy grail of system scalability is to have throughput
                                    change exactly in step with resources.
                                </p>
                                <p>
                                    Consider a system based on a cluster of servers. If the cluster is expanded, for
                                    example, by doubling in size, then what throughput can be achieved? If the new
                                    cluster can handle twice the volume of transactions, then the system is exhibiting
                                    “perfect linear scaling.” This is very difficult to achieve in practice, especially
                                    over a wide range of possible loads.
                                </p>
                                <p>
                                    System scalability is dependent upon a number of factors, and is not normally a
                                    simple constant factor. It is very common for a system to scale close to linearly
                                    for some range of resources, but then at higher loads to encounter some limitation
                                    that prevents perfect scaling.
                                </p>
                            </div>
                        </section>
                        <section data-pdf-bookmark="Degradation" data-type="sect2">
                            <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.7">
                                <h2>
                                    Degradation
                                </h2>
                                <p>
                                    If we increase the load on a system, either by increasing the number of requests (or
                                    clients) or by increasing the speed requests arrive at, then we may see a change in
                                    the observed latency and/or throughput.
                                    <a data-primary="performance metrics" data-secondary="degradation"
                                       data-type="indexterm" id="idm139848331768512">
                                    </a>
                                    <a data-primary="degradation" data-secondary="about" data-type="indexterm"
                                       id="idm139848331767536">
                                    </a>
                                </p>
                                <p>
                                    Note that this change is dependent on utilization. If the system is underutilized,
                                    then there should be some slack before observables change, but if resources are
                                    fully
                                    utilized then we would expect to see throughput stop increasing, or latency
                                    increase.
                                    These changes are usually called the degradation of the system under additional
                                    load.
                                </p>
                            </div>
                        </section>
                        <section data-pdf-bookmark="Connections Between the Observables" data-type="sect2">
                            <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.8">
                                <h2>
                                    Connections Between the Observables
                                </h2>
                                <p>
                                    The behavior of the various performance observables is usually connected in some
                                    manner.
                                    <a data-primary="performance" data-secondary="connections between observables"
                                       data-type="indexterm" id="idm139848331763664">
                                    </a>
                                    The details of this connection will depend upon whether the system is running at
                                    peak utility. For example, in general, the utilization will change as the load on a
                                    system increases.
                                    <a data-primary="utilization"
                                       data-secondary="connections with other performance observables"
                                       data-type="indexterm" id="idm139848331762304">
                                    </a>
                                    However, if the system is underutilized, then increasing load may not appreciably
                                    increase utilization. Conversely, if the system is already stressed, then the effect
                                    of increasing load may be felt in another observable.
                                </p>
                                <p>
                                    As another example, scalability and degradation both represent the change in
                                    behavior of a system as more load is added.
                                    <a data-primary="scalability"
                                       data-secondary="connections with other performance observables"
                                       data-type="indexterm" id="idm139848331760496">
                                    </a>
                                    <a data-primary="degradation"
                                       data-secondary="connections with other performance observables"
                                       data-type="indexterm" id="idm139848331759488">
                                    </a>
                                    For scalability, as the load is increased, so are available resources, and the
                                    central question is whether the system can make use of them. On the other hand, if
                                    load is added but additional resources are not provided, degradation of some
                                    performance observable (e.g., latency) is the expected outcome.
                                </p>
                                <div data-type="note" epub:type="note">
                                    <h6>
                                        Note
                                    </h6>
                                    <p>
                                        In rare cases, additional load can cause counterintuitive results. For example,
                                        if the change in load causes some part of the system to switch to a more
                                        resource-intensive but higher-performance mode, then the overall effect can be
                                        to reduce latency, even though more requests are being received.
                                    </p>
                                </div>
                                <p>
                                    To take one example, in
                                    <a data-type="xref" href="ch09.html#pracjavaperf-CHP-9">
                                        Chapter 9
                                    </a>
                                    we will discuss HotSpot’s JIT compiler in detail. To be considered eligible for JIT
                                    compilation, a method has to be executed in interpreted mode “sufficiently
                                    frequently.” So it is possible at low load to have key methods stuck in interpreted
                                    mode, but for those to become eligible for compilation at higher loads due to
                                    increased calling frequency on the methods. This causes later calls to the same
                                    method to run much, much faster than earlier executions.
                                </p>
                                <p>
                                    Different workloads can have very different characteristics.
                                    <a data-primary="latency"
                                       data-secondary="connections with other performance observables"
                                       data-type="indexterm" id="idm139848331754528">
                                    </a>
                                    For example, a trade on
                                    the financial markets, viewed end to end, may have an execution time (i.e., latency)
                                    of hours or even days. However, millions of them may be in progress at a major
                                    bank at any given time. Thus, the capacity of the system is very large, but the
                                    latency is also large.
                                </p>
                                <p>
                                    However, let’s consider only a single subsystem within the bank. The matching of a
                                    buyer and a seller (which is essentially the parties agreeing on a price) is known
                                    as
                                    <em>
                                        order matching
                                    </em>
                                    . This individual subsystem may have only hundreds of pending
                                    orders at any given time, but the latency from order acceptance to completed match
                                    may be as little as 1 millisecond (or even less in the case of “low-latency”
                                    trading).
                                </p>
                                <p>
                                    In this section we have met the most frequently encountered performance observables.
                                    Occasionally slightly different definitions, or even different metrics, are used,
                                    but
                                    in most cases these will be the basic system numbers that will normally be used
                                    to guide performance tuning, and act as a taxonomy for discussing the performance of
                                    systems of interest.
                                    <a data-primary="performance" data-secondary="taxonomy for"
                                       data-startref="ix_perf1tax" data-type="indexterm" id="idm139848331751056">
                                    </a>
                                </p>
                            </div>
                        </section>
                    </div>
                </section>
                <section data-pdf-bookmark="Reading Performance Graphs" data-type="sect1">
                    <div class="sect1" id="pracjavaperf-CHP-1-SECT-5">
                        <h1>
                            Reading Performance Graphs
                        </h1>
                        <p>
                            To conclude this chapter, let’s look at some common patterns of behavior
                            that occur in performance tests.
                            <a data-primary="performance" data-secondary="reading performance graphs"
                               data-type="indexterm" id="idm139848331747728">
                            </a>
                            We will explore these by looking at graphs of real
                            observables, and we will encounter many other examples of graphs of our data as we
                            proceed.
                        </p>
                        <p>
                            The graph in
                            <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-1">
                                Figure 1-1
                            </a>
                            shows sudden, unexpected degradation of performance (in this case, latency) under increasing
                            load—commonly called a
                            <em>
                                performance elbow
                            </em>
                            .
                            <a data-primary="performance elbow" data-type="indexterm" id="idm139848331744624">
                            </a>
                        </p>
                        <figure class="width_set_50">
                            <div class="figure" id="pracjavaperf-CHP-1-FIG-1">
                                <img alt="opjv 0101" height="897"
                                     src="test/library/view/optimizing-java/9781492039259/assets/opjv_0101.png"
                                     width="941"/>
                                <h6>
        <span class="label">
         Figure 1-1.
        </span>
                                    A performance elbow
                                </h6>
                            </div>
                        </figure>
                        <p>
                            By contrast,
                            <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-2">
                                Figure 1-2
                            </a>
                            shows the much happier case of
                            throughput scaling almost linearly as machines are added to a cluster.
                            <a data-primary="linear scaling" data-type="indexterm" id="idm139848331740224">
                            </a>
                            This is close to ideal behavior, and is only likely to be achieved in extremely favorable
                            circumstances—e.g., scaling a stateless protocol with no need for session affinity with a
                            single server.
                        </p>
                        <figure class="width_set_50">
                            <div class="figure" id="pracjavaperf-CHP-1-FIG-2">
                                <img alt="opjv 0102" height="954"
                                     src="test/library/view/optimizing-java/9781492039259/assets/opjv_0102.png"
                                     width="954"/>
                                <h6>
        <span class="label">
         Figure 1-2.
        </span>
                                    Near-linear scaling
                                </h6>
                            </div>
                        </figure>
                        <p>
                            In
                            <a data-type="xref" href="ch12.html#pracjavaperf-CHP-12">
                                Chapter 12
                            </a>
                            we will meet Amdahl’s Law,
                            <a data-primary="Amdahl's Law" data-type="indexterm" id="idm139848331735680">
                            </a>
                            <a data-primary="scalability" data-secondary="Amdahl's Law" data-type="indexterm"
                               id="idm139848331735008">
                            </a>
                            named for the famous computer scientist (and “father of the mainframe”) Gene Amdahl of IBM.
                            <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-3">
                                Figure 1-3
                            </a>
                            shows a graphical representation of his fundamental constraint on scalability; it shows the
                            maximum possible speedup as a function of the number of processors devoted to the task.
                        </p>
                        <figure>
                            <div class="figure" id="pracjavaperf-CHP-1-FIG-3">
                                <img alt="opjv 0103" height="900"
                                     src="test/library/view/optimizing-java/9781492039259/assets/opjv_0103.png"
                                     width="1440"/>
                                <h6>
        <span class="label">
         Figure 1-3.
        </span>
                                    Amdahl’s Law
                                </h6>
                            </div>
                        </figure>
                        <p>
                            We display three cases: where the underlying task is 75%, 90%, and 95% parallelizable.
                            This clearly shows that whenever the workload has any piece at all that must be performed
                            serially, linear scalability is impossible, and there are strict limits on how much
                            scalability can be achieved.
                            This justifies the commentary around
                            <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-2">
                                Figure 1-2
                            </a>
                            —even in the best cases linear scalability is all but impossible to achieve.
                        </p>
                        <p>
                            The limits imposed by Amdahl’s Law are surprisingly restrictive.
                            Note in particular that the x-axis of the graph is logarithmic, and so even with an
                            algorithm that is (only) 5% serial, 32 processors are needed for a factor-of-12 speedup.
                            Even worse, no matter how many cores are used, the maximum speedup is only a factor of 20
                            for that algorithm.
                            In practice, many algorithms are far more than 5% serial, and so have a more constrained
                            maximum possible speedup.
                            <a data-primary="memory management"
                               data-secondary="healthy memory usage and allocation rate" data-type="indexterm"
                               id="idm139848331861952">
                            </a>
                        </p>
                        <p>
                            As we will see in
                            <a data-type="xref" href="ch06.html#pracjavaperf-CHP-6">
                                Chapter 6
                            </a>
                            , the underlying technology in the JVM’s garbage collection subsystem naturally gives rise
                            to a “sawtooth” pattern of memory used for healthy applications that aren’t under stress.
                            We can see an example in
                            <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-4">
                                Figure 1-4
                            </a>
                            .
                        </p>
                        <figure>
                            <div class="figure" id="pracjavaperf-CHP-1-FIG-4">
                                <img alt="opjv 0104" height="890"
                                     src="test/library/view/optimizing-java/9781492039259/assets/opjv_0104.png"
                                     width="1134"/>
                                <h6>
        <span class="label">
         Figure 1-4.
        </span>
                                    Healthy memory usage
                                </h6>
                            </div>
                        </figure>
                        <p class="pagebreak-before">
                            In
                            <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-5">
                                Figure 1-5
                            </a>
                            , we show another memory graph that can be of great importance when performance tuning an
                            application’s memory allocation rate. This short example shows a sample application
                            (calculating Fibonnaci numbers). It clearly displays a sharp drop in the allocation rate at
                            around the 90 second mark.
                        </p>
                        <p>
                            Other graphs from the same tool (jClarity Censum) show that the
                            application starts to suffer from major garbage collection problems at
                            this time, and so the application is unable to allocate sufficient
                            memory due to CPU contention from the garbage collection threads.
                        </p>
                        <p>
                            We can also spot that the allocation subsystem is running hot—allocating over 4 GB per
                            second. This is well above the recommended
                            maximum capacity of most modern systems (including server class
                            hardware). We will have much more to say about the subject of
                            allocation when we discuss garbage collection in
                            <a data-type="xref" href="ch06.html#pracjavaperf-CHP-6">
                                Chapter 6
                            </a>
                            .
                        </p>
                        <figure>
                            <div class="figure" id="pracjavaperf-CHP-1-FIG-5">
                                <img alt="opjv 0105" height="758"
                                     src="test/library/view/optimizing-java/9781492039259/assets/opjv_0105.png"
                                     width="1133"/>
                                <h6>
        <span class="label">
         Figure 1-5.
        </span>
                                    Sample problematic allocation rate
                                </h6>
                            </div>
                        </figure>
                        <p>
                            In the case where a system has a resource leak,
                            <a data-primary="resource leaks" data-type="indexterm" id="idm139848331850192">
                            </a>
                            it is far more common for it to
                            manifest in a manner like that shown in
                            <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-6">
                                Figure 1-6
                            </a>
                            ,
                            where an observable (in this case latency) slowly degrades as the load is ramped
                            up, before hitting an inflection point where the system rapidly degrades.
                            <a data-primary="latency" data-secondary="degradation with system resource leak"
                               data-type="indexterm" id="idm139848331848320">
                            </a>
                        </p>
                        <figure class="width_set_50">
                            <div class="figure" id="pracjavaperf-CHP-1-FIG-6">
                                <img alt="opjv 0106" height="1051"
                                     src="test/library/view/optimizing-java/9781492039259/assets/opjv_0106.png"
                                     width="1175"/>
                                <h6>
        <span class="label">
         Figure 1-6.
        </span>
                                    Degrading latency under higher load
                                </h6>
                            </div>
                        </figure>
                    </div>
                </section>
                <section data-pdf-bookmark="Summary" data-type="sect1">
                    <div class="sect1" id="idm139848331749216">
                        <h1>
                            Summary
                        </h1>
                        <p>
                            In this chapter we have started to discuss what Java performance is and is not. We have
                            introduced the fundamental topics of empirical science and measurement, and the basic
                            vocabulary and observables that a good performance exercise will use. Finally, we have
                            introduced some common cases that are often seen within the results obtained from
                            performance tests. Let’s move on and begin our discussion of some of the major aspects of
                            the JVM, and set the scene for understanding what makes JVM-based performance optimization a
                            particularly complex problem.
                            <a data-primary="performance" data-startref="ix_perf1" data-type="indexterm"
                               id="idm139848331843264">
                            </a>
                        </p>
                    </div>
                </section>
            </div>
        </section>
    </div>
</div>
</body>
</html>
