<html>
                            <head>
                               <meta charset="utf-8"/>
                               <link rel="stylesheet" href="style.css" /> 
                               <link rel="stylesheet" href="style2.css" />
                            </head>
                            <body>
<div class="page"><div id="sbo-rt-content">
 <figure data-type="cover">
  <img alt="cover" height="1574" src="library/view/optimizing-java/9781492039259/assets/cover.png" width="1200"/>
 </figure>
</div>
</div>
<div class="page"><div id="sbo-rt-content">
 <section data-pdf-bookmark="Optimizing Java" data-type="titlepage" epub:type="titlepage">
  <div class="preface" id="idm139848332082752">
   <h1>
    Optimizing Java
   </h1>
   <p data-type="subtitle" epub:type="subtitle">
    Practical Techniques for Improving JVM Application Performance
   </p>
   <p class="author">
    Benjamin J. Evans, James Gough, and Chris Newland
   </p>
  </div>
 </section>
</div>
</div>
<div class="page"><div id="sbo-rt-content">
 <section data-pdf-bookmark="Optimizing Java" data-type="copyright-page" epub:type="copyright-page">
  <div class="preface" id="idm139848332006928">
   <h1>
    Optimizing Java
   </h1>
   <p class="author">
    by
    <span class="firstname">
     Benjamin
    </span>
    <span class="othername mi">
     J.
    </span>
    <span class="surname">
     Evans
    </span>
    ,
    <span class="firstname">
     James
    </span>
    <span class="surname">
     Gough
    </span>
    , and
    <span class="firstname">
     Chris
    </span>
    <span class="surname">
     Newland
    </span>
   </p>
   <p class="copyright">
    Copyright © 2018 Benjamin J. Evans, James Gough, and Chris Newland. All rights reserved.
   </p>
   <p class="printlocation">
    Printed in the United States of America.
   </p>
   <p class="publisher">
    Published by
    <span class="publishername">
     O’Reilly Media, Inc.
    </span>
    , 1005 Gravenstein Highway North, Sebastopol, CA 95472.
   </p>
   <p>
    O’Reilly books may be purchased for educational, business, or sales
    promotional use. Online editions are also available for most titles (
    <a href="http://oreilly.com/safari">
     http://oreilly.com/safari
    </a>
    ). For more information, contact our corporate/institutional sales
    department: 800-998-9938 or
    <span data-type="email">
     <em>
      corporate@oreilly.com
     </em>
    </span>
    .
   </p>
   <ul class="stafflist">
    <li>
     <span class="staffrole">
      Editors:
     </span>
     Susan Conant and Virginia Wilson
    </li>
    <li>
     <span class="staffrole">
      Production Editor:
     </span>
     Colleen Cole
    </li>
    <li>
     <span class="staffrole">
      Copyeditor:
     </span>
     Rachel Monaghan
    </li>
    <li>
     <span class="staffrole">
      Proofreader:
     </span>
     Rachel Head
    </li>
    <li>
     <span class="staffrole">
      Indexer:
     </span>
     Ellen Troutman-Zaig
    </li>
    <li>
     <span class="staffrole">
      Interior Designer:
     </span>
     David Futato
    </li>
    <li>
     <span class="staffrole">
      Cover Designer:
     </span>
     Randy Comer
    </li>
    <li>
     <span class="staffrole">
      Illustrator:
     </span>
     Anna Evans
    </li>
    <li>
     <span class="staffrole">
      Technical Reviewers:
     </span>
     Julian Templeman, Michael Hsu, Alex Blewitt, Dmitry Vyazelenko
    </li>
   </ul>
   <ul class="printings">
    <li>
     <span class="printedition">
      May 2018:
     </span>
     First Edition
    </li>
   </ul>
   <!--Add additional revdate spans below as needed.-->
   <div>
    <h1 class="revisions">
     Revision History for the First Edition
    </h1>
    <ul class="releases">
     <li>
      <span class="revdate">
       2018-04-12:
      </span>
      First Release
     </li>
    </ul>
   </div>
   <p class="errata">
    See
    <a href="http://oreilly.com/catalog/errata.csp?isbn=9781492025795">
     http://oreilly.com/catalog/errata.csp?isbn=9781492025795
    </a>
    for release details.
   </p>
   <div class="legal">
    <p>
     The O’Reilly logo is a registered trademark of O’Reilly Media, Inc.
     <em>
      Optimizing Java
     </em>
     , the cover image, and related trade dress are trademarks
      of O’Reilly Media, Inc.
    </p>
    <p>
     While the publisher and the authors have used good faith efforts to
      ensure that the information and instructions contained in this work are
      accurate, the publisher and the authors disclaim all responsibility for
      errors or omissions, including without limitation responsibility for
      damages resulting from the use of or reliance on this work. Use of the
      information and instructions contained in this work is at your own risk.
      If any code samples or other technology this work contains or describes is
      subject to open source licenses or the intellectual property rights of
      others, it is your responsibility to ensure that your use thereof complies
      with such licenses and/or rights.
     <!--PROD: Uncomment the following sentence if appropriate and add it to the 
        above para:-->
     <!--This book is not intended as [legal/medical/financial; use the appropriate
        reference] advice. Please consult a qualified professional if you 
        require [legal/medical/financial] advice.-->
    </p>
   </div>
   <div class="copyright-bottom">
    <p class="isbn">
     978-1-492-02579-5
    </p>
    <p class="printer">
     [LSI]
    </p>
   </div>
  </div>
 </section>
</div>
</div>
<div class="page"><div id="sbo-rt-content">
 <section data-pdf-bookmark="Dedication" data-type="dedication" epub:type="dedication">
  <div class="dedication" id="idm139848325935344">
   <h1>
    Dedication
   </h1>
   <p>
    This book is dedicated to my wife, Anna, who not only illustrated it beautifully, but also helped edit portions and, crucially, was often the first person I bounced ideas off.
   </p>
   <p data-type="attribution">
    —Benjamin J. Evans
   </p>
   <br/>
   <br/>
   <br/>
   <p>
    This book is dedicated to my incredible family Megan, Emily, and Anna. Writing would not have been possible without their help and support. I’d also like to thank my parents, Heather and Paul, for encouraging me to learn and their constant support.
   </p>
   <p>
    I’d also like to thank Benjamin Evans for his guidance and friendship—it’s been a pleasure working together again.
   </p>
   <p data-type="attribution">
    —James Gough
   </p>
   <br/>
   <br/>
   <br/>
   <p>
    This book is dedicated to my wife, Reena, who supported and encouraged my efforts and to my sons, Joshua and Hugo, may they grow up with inquisitive minds.
   </p>
   <p data-type="attribution">
    —Chris Newland
   </p>
  </div>
 </section>
</div>
</div>
<div class="page"><div id="sbo-rt-content">
 <section data-pdf-bookmark="Foreword" data-type="foreword" epub:type="foreword">
  <div class="preface" id="idm139848332101072">
   <h1>
    Foreword
   </h1>
   <p>
    How do you define performance?
   </p>
   <p>
    Most developers, when asked about the performance of their application, will assume some measure of speed is requested. Something like transactions per second, or gigabytes of data processed…getting a lot of work done in the shortest amount of time possible. If you’re an application architect, you may measure performance in broader metrics. You may be more concerned about resource utilization than straight-line execution. You might pay more attention to the performance of connections between services than of the services themselves. If you make business decisions for your company, application performance will probably not be measured in time as often as it is measured in dollars. You may argue with developers and architects about resource allocation, weighing the cost of devops against the time it takes to do the company’s work.
   </p>
   <p>
    And regardless of which role you identify with, all these metrics are important.
   </p>
   <p>
    I started out developing Java applications in 1996. I had just moved from my first job writing AppleScript CGIs for the University of Minnesota’s business school to maintaining server-side Perl applications for the web development team. Java was very new then—the first stable version, 1.0.2, was released earlier that year—and I was tasked with finding something useful to build.
   </p>
   <p>
    Back in those days, the best way to get performance out of a Java application was to write it in some other language. This was before Java had a Just-in-Time (JIT) compiler, before parallel and concurrent garbage collectors, and long before the server side would become dominated by Java technology. But many of us wanted to use Java, and we developed all sorts of tricks to make our code run well. We wrote gigantic methods to avoid method dispatch overhead. We pooled and reused objects because garbage collection was slow and disruptive. We used lots of global state and static methods. We wrote truly awful Java code, but it worked…for a little while.
   </p>
   <p>
    In 1999, things started to change.
   </p>
   <p>
    After years struggling to use Java for anything demanding speed, JIT technologies started to reach us. With compilers that could inline methods, the number of method calls became less important than breaking up our giant monoliths into smaller pieces. We gleefully embraced object-oriented design, splitting our methods into tiny chunks and wrapping interfaces around everything. We marveled at how every release of Java would run things just a little bit better, because we were writing good Java code and the JIT compiler loved it. Java soared past other technologies on the server, leading us to build larger and more complex apps with richer abstractions.
   </p>
   <p>
    At the same time, garbage collectors were rapidly improving. Now the overhead of pooling would very frequently overshadow the cost of allocation. Many garbage collectors offered multithreaded operation, and we started to see low-pause, nearly concurrent GCs that stayed out of our applications’ way. The standard practice moved toward a carefree creating and throwing away of objects with the promise that a sufficiently smart GC would eventually make it all OK. And it worked…for a little while.
   </p>
   <p>
    The problem with technology is that it always invalidates itself. As JIT and GC technologies have improved, the paths to application performance have become tricky to navigate. Even though JVMs can optimize our code and make objects almost free, the demands of applications and users continue to grow.
   </p>
   <p>
    Some of the time, maybe even most of the time, the “good” coding patterns prevail: small methods inline properly, interface and type checks become inexpensive, native code produced by the JIT compiler is compact and efficient. But other times we need to hand-craft our code, dial back abstractions and architecture in deference to the limitations of the compiler and CPU. Some of the time, objects really are free and we can ignore the fact that we’re consuming memory bandwidth and GC cycles. Other times we’re dealing with terabyte-scale (or larger) datasets that put stress on even the best garbage collectors and memory subsystems.
   </p>
   <p>
    The answer to the performance question these days is to know your tools. And frequently, that means knowing not just how Java the language works, but also how JVM libraries, memory, the compiler, GCs, and the hardware your apps run on are interacting. In my work on the JRuby project, I’ve learned an immutable truth about the JVM: there’s no single solution for all performance problems, but for all performance problems there are solutions. The trick is finding those solutions and piecing together the ones that meet your needs best. Now you have a secret weapon in these performance battles: the book you are about to read.
   </p>
   <p>
    Turn the page, friends, and discover the wealth of tools and techniques available to you. Learn how to balance application design with available resources. Learn how to monitor and tune the JVM. Learn how to make use of the latest Java technologies that are more efficient than old libraries and patterns. Learn how to make Java fly.
   </p>
   <p>
    It’s an exciting time to be a Java developer, and there have never been so many opportunities to build efficient and responsive applications on the Java platform. Let’s get started.
   </p>
   <p class="byline">
    Charlie Nutter
   </p>
   <p class="byline cont">
    Principal Software Engineer,
   </p>
   <p class="byline cont">
    Red Hat Middleware
   </p>
  </div>
 </section>
</div>
</div>
<div class="page"><div id="sbo-rt-content">
 <section data-pdf-bookmark="Preface" data-type="preface" epub:type="preface">
  <div class="preface" id="pracjavaperf-PREF">
   <h1>
    Preface
   </h1>
   <section data-pdf-bookmark="Conventions Used in This Book" data-type="sect1">
    <div class="sect1" id="idm139848331939328">
     <h1>
      Conventions Used in This Book
     </h1>
     <p>
      The following typographical conventions are used in this book:
     </p>
     <dl>
      <dt>
       <em>
        Italic
       </em>
      </dt>
      <dd>
       <p>
        Indicates new terms, URLs, email addresses, filenames, and file extensions.
       </p>
      </dd>
      <dt>
       <code>
        Constant width
       </code>
      </dt>
      <dd>
       <p>
        Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.
       </p>
      </dd>
      <dt>
       <code>
        &lt;constant width&gt;
       </code>
       in angle brackets
      </dt>
      <dd>
       <p>
        Shows text that should be replaced with user-supplied values or by values determined by context.
       </p>
      </dd>
     </dl>
     <div data-type="tip">
      <h6>
       Tip
      </h6>
      <p>
       This element signifies a tip or suggestion.
      </p>
     </div>
     <div data-type="note" epub:type="note">
      <h6>
       Note
      </h6>
      <p>
       This element signifies a general note.
      </p>
     </div>
     <div data-type="warning" epub:type="warning">
      <h6>
       Warning
      </h6>
      <p>
       This element indicates a warning or caution.
      </p>
     </div>
    </div>
   </section>
   <section data-pdf-bookmark="Using Code Examples" data-type="sect1">
    <div class="sect1" id="idm139848332030864">
     <h1>
      Using Code Examples
     </h1>
     <!--PROD: Please reach out to author to find out if they will be uploading code examples to oreilly.com or their own site (e.g., GitHub). If there is no code download, delete this whole section. If there is, when you email digidist with the link, let them know what you filled in for title_title (should be as close to book title as possible, i.e., learning_python_2e). This info will determine where digidist loads the files.-->
     <p>
      Supplemental material (code examples, exercises, etc.) is available for download at
      <a href="http://bit.ly/optimizing-java-1e-code-examples">
       <em class="hyperlink">
        http://bit.ly/optimizing-java-1e-code-examples
       </em>
      </a>
      .
     </p>
     <p>
      This book is here to help you get your job done. In general, if example code is offered with this book, you may use it in your programs and documentation. You do not need to contact us for permission unless you’re reproducing a significant portion of the code. For example, writing a program that uses several chunks of code from this book does not require permission. Selling or distributing a CD-ROM of examples from O’Reilly books does require permission. Answering a question by citing this book and quoting example code does not require permission. Incorporating a significant amount of example code from this book into your product’s documentation does require permission.
     </p>
     <p>
      We appreciate, but do not require, attribution. An attribution usually includes the title, author, publisher, and ISBN. For example: “
      <em>
       Optimizing Java
      </em>
      by Benjamin J. Evans, James Gough, and Chris Newland (O’Reilly). Copyright 2018 Benjamin J. Evans, James Gough, and Chris Newland, 978-1-492-02579-5.”
     </p>
     <p>
      If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at
      <a class="email" href="mailto:permissions@oreilly.com">
       <em>
        permissions@oreilly.com
       </em>
      </a>
      .
     </p>
    </div>
   </section>
   <section data-pdf-bookmark="O’Reilly Safari" data-type="sect1">
    <div class="sect1" id="idm139848332013264">
     <h1>
      O’Reilly Safari
     </h1>
     <div class="safarienabled" data-type="note" epub:type="note">
      <h6>
       Note
      </h6>
      <p>
       <a class="orm:hideurl" href="http://oreilly.com/safari">
        <em class="hyperlink">
         Safari
        </em>
       </a>
       (formerly Safari Books Online) is a membership-based training and reference platform for enterprise, government, educators, and individuals.
      </p>
     </div>
     <p>
      Members have access to thousands of books, training videos, Learning Paths, interactive tutorials, and curated playlists from over 250 publishers, including O’Reilly Media, Harvard Business Review, Prentice Hall Professional, Addison-Wesley Professional, Microsoft Press, Sams, Que, Peachpit Press, Adobe, Focal Press, Cisco Press, John Wiley &amp; Sons, Syngress, Morgan Kaufmann, IBM Redbooks, Packt, Adobe Press, FT Press, Apress, Manning, New Riders, McGraw-Hill, Jones &amp; Bartlett, and Course Technology, among others.
     </p>
     <p>
      For more information, please visit
      <a class="orm:hideurl" href="http://oreilly.com/safari">
       <em>
        http://oreilly.com/safari
       </em>
      </a>
      .
     </p>
    </div>
   </section>
   <section class="pagebreak-before less_space" data-pdf-bookmark="How to Contact Us" data-type="sect1">
    <div class="sect1" id="idm139848331681104">
     <h1>
      How to Contact Us
     </h1>
     <p>
      Please address comments and questions concerning this book to the publisher:
     </p>
     <ul class="simplelist">
      <li>
       O’Reilly Media, Inc.
      </li>
      <li>
       1005 Gravenstein Highway North
      </li>
      <li>
       Sebastopol, CA 95472
      </li>
      <li>
       800-998-9938 (in the United States or Canada)
      </li>
      <li>
       707-829-0515 (international or local)
      </li>
      <li>
       707-829-0104 (fax)
      </li>
     </ul>
     <p>
      We have a web page for this book, where we list errata, examples, and any additional information. You can access this page at
      <a href="http://bit.ly/optimizing-java">
       <em class="hyperlink">
        http://bit.ly/optimizing-java
       </em>
      </a>
      .
     </p>
     <!--Don't forget to update the link above.-->
     <p>
      To comment or ask technical questions about this book, send email to
      <a class="email" href="mailto:bookquestions@oreilly.com">
       <em>
        bookquestions@oreilly.com
       </em>
      </a>
      .
     </p>
     <p>
      For more information about our books, courses, conferences, and news, see our website at
      <a href="http://www.oreilly.com">
       <em class="hyperlink">
        http://www.oreilly.com
       </em>
      </a>
      .
     </p>
     <p>
      Find us on Facebook:
      <a href="http://facebook.com/oreilly">
       <em class="hyperlink">
        http://facebook.com/oreilly
       </em>
      </a>
     </p>
     <p>
      Follow us on Twitter:
      <a href="http://twitter.com/oreillymedia">
       <em class="hyperlink">
        http://twitter.com/oreillymedia
       </em>
      </a>
     </p>
     <p>
      Watch us on YouTube:
      <a href="http://www.youtube.com/oreillymedia">
       <em class="hyperlink">
        http://www.youtube.com/oreillymedia
       </em>
      </a>
     </p>
    </div>
   </section>
   <section data-pdf-bookmark="Acknowledgments" data-type="sect1">
    <div class="sect1" id="idm139848331680576">
     <h1>
      Acknowledgments
     </h1>
     <p>
      The authors would like to thank a large number of people for their
invaluable assistance.
     </p>
     <p>
      For writing the foreword:
     </p>
     <ul>
      <li>
       <p>
        Charlie Nutter
       </p>
      </li>
     </ul>
     <p>
      For providing highly specialist technical help, including information
and knowledge not available anywhere else:
     </p>
     <ul>
      <li>
       <p>
        Christine Flood
       </p>
      </li>
      <li>
       <p>
        Chris Seaton
       </p>
      </li>
      <li>
       <p>
        Kirk Pepperdine
       </p>
      </li>
      <li>
       <p>
        Simon Ritter
       </p>
      </li>
      <li>
       <p>
        Monica Beckwith
       </p>
      </li>
      <li>
       <p>
        David Jones
       </p>
      </li>
      <li>
       <p>
        Richard Warburton
       </p>
      </li>
      <li>
       <p>
        Stephen Connolly
       </p>
      </li>
      <li>
       <p>
        Jaroslav Tulach
       </p>
      </li>
     </ul>
     <p>
      For general detail, encouragement, advice and introductions:
     </p>
     <ul>
      <li>
       <p>
        George Ball
       </p>
      </li>
      <li>
       <p>
        Steve Poole
       </p>
      </li>
      <li>
       <p>
        Richard Pollock
       </p>
      </li>
      <li>
       <p>
        Andrew Binstock
       </p>
      </li>
     </ul>
     <p>
      Our technical reviewers:
     </p>
     <ul>
      <li>
       <p>
        Michael Hsu
       </p>
      </li>
      <li>
       <p>
        Dmitry Vyazelenko
       </p>
      </li>
      <li>
       <p>
        Julian Templeman
       </p>
      </li>
      <li>
       <p>
        Alex Blewitt
       </p>
      </li>
     </ul>
     <p>
      The O’Reilly Team:
     </p>
     <ul>
      <li>
       <p>
        Virginia Wilson
       </p>
      </li>
      <li>
       <p>
        Susan Conant
       </p>
      </li>
      <li>
       <p>
        Colleen Cole
       </p>
      </li>
      <li>
       <p>
        Rachel Monaghan
       </p>
      </li>
      <li>
       <p>
        Nan Barber
       </p>
      </li>
      <li>
       <p>
        Brian Foster
       </p>
      </li>
      <li>
       <p>
        Lindsay Ventimiglia
       </p>
      </li>
      <li>
       <p>
        Maureen Spencer
       </p>
      </li>
      <li>
       <p>
        Heather Scherer
       </p>
      </li>
     </ul>
    </div>
   </section>
  </div>
 </section>
</div>
</div>
<div class="page"><div id="sbo-rt-content">
 <section class="pagenumrestart" data-pdf-bookmark="Chapter 1. Optimization and Performance Defined" data-type="chapter" epub:type="chapter">
  <div class="chapter" id="pracjavaperf-CHP-1">
   <h1>
    <span class="label">
     Chapter 1.
    </span>
    Optimization and Performance Defined
   </h1>
   <p>
    Optimizing the performance of Java (or any other sort of code) is often seen as a Dark Art.
    <a data-primary="performance" data-type="indexterm" id="ix_perf1">
    </a>
    There’s a mystique about performance analysis—it’s commonly viewed as a craft practiced by the “lone hacker, who is tortured and deep thinking” (one of Hollywood’s favorite tropes about computers and the people who operate them).
The image is one of a single individual who can see deeply into a system and come up with a magic solution that makes the system work faster.
    <a data-primary="performance optimizations" data-seealso="performance" data-type="indexterm" id="idm139848331880512">
    </a>
   </p>
   <p>
    This image is often coupled with the unfortunate (but all-too-common) situation where performance is a second-class concern of the software teams.
This sets up a scenario where analysis is only done once the system is already in trouble, and so needs a performance “hero” to save it.
The reality, however, is a little different.
   </p>
   <p>
    The truth is that performance analysis is a weird blend of hard empiricism and squishy human psychology.
What matters is, at one and the same time, the absolute numbers of observable metrics and how the end users and stakeholders
    <em>
     feel
    </em>
    about them.
The resolution of this apparent paradox is the subject of the rest of this book.
   </p>
   <section data-pdf-bookmark="Java Performance—The Wrong Way" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-1-SECT-1">
     <h1>
      Java Performance—The Wrong Way
     </h1>
     <p>
      For many years, one of the top three hits on Google for “Java performance tuning” was an article from 1997–8, which had been ingested into the index very early in Google’s history.
      <a data-primary="performance" data-secondary="misconceptions about Java performance" data-type="indexterm" id="idm139848331875312">
      </a>
      The page had presumably stayed close to the top because its initial ranking served to actively drive traffic to it, creating a feedback loop.
     </p>
     <p>
      The page housed advice that was completely out of date, no longer true, and in many cases detrimental to applications.
However, its favored position in the search engine results caused many, many developers to be exposed to terrible advice.
     </p>
     <p>
      For example, very early versions of Java had terrible method dispatch performance.
As a workaround, some Java developers advocated avoiding writing small methods and instead writing monolithic methods.
Of course, over time, the performance of virtual dispatch greatly improved. Not only that, but with modern Java Virtual Machines (JVMs) and especially automatic managed inlining, virtual dispatch has now been eliminated at the majority of call sites.
      <a data-primary="Java Virtual Machines" data-see="JVMs" data-type="indexterm" id="idm139848331872464">
      </a>
      Code that followed the “lump everything into one method” advice is now at a substantial disadvantage, as it is very unfriendly to modern Just-in-Time (JIT) compilers.
     </p>
     <p>
      There’s no way of knowing how much damage was done to the performance of applications that were subjected to the bad advice, but this case neatly demonstrates the dangers of not using a quantitative and verifiable approach to performance. It also provides another excellent example of why you shouldn’t believe everything you read
on the internet.
     </p>
     <div data-type="note" epub:type="note">
      <h6>
       Note
      </h6>
      <p>
       The execution speed of Java code is highly dynamic and fundamentally depends on the underlying Java Virtual Machine.
       <a data-primary="JVMs (Java Virtual Machines)" data-secondary="execution speed of code and" data-type="indexterm" id="idm139848331797824">
       </a>
       An old piece of Java code may well execute faster on a more recent JVM, even without recompiling the Java source code.
      </p>
     </div>
     <p>
      As you might imagine, for this reason (and others we will discuss later) this book is not a cookbook of performance tips to apply to your code. Instead, we focus on a range of aspects that come together to produce good performance engineering:
     </p>
     <ul>
      <li>
       <p>
        Performance methodology within the overall software lifecycle
       </p>
      </li>
      <li>
       <p>
        Theory of testing as applied to performance
       </p>
      </li>
      <li>
       <p>
        Measurement, statistics, and tooling
       </p>
      </li>
      <li>
       <p>
        Analysis skills (both systems and data)
       </p>
      </li>
      <li>
       <p>
        Underlying technology and mechanisms
       </p>
      </li>
     </ul>
     <p>
      Later in the book, we will introduce some heuristics and code-level techniques for optimization, but these all come with caveats and tradeoffs that the developer should be aware of before using them.
     </p>
     <div data-type="tip">
      <h6>
       Tip
      </h6>
      <p>
       Please do not skip ahead to those sections and start applying the techniques detailed without properly understanding the context in which the advice is given.
All of these techniques are capable of doing more harm than good if you lack a proper understanding of how they should be applied.
      </p>
     </div>
     <p class="pagebreak-before">
      In general, there are:
     </p>
     <ul>
      <li>
       <p>
        No magic “go faster” switches for the JVM
       </p>
      </li>
      <li>
       <p>
        No “tips and tricks” to make Java run faster
       </p>
      </li>
      <li>
       <p>
        No secret algorithms that have been hidden from you
       </p>
      </li>
     </ul>
     <p>
      As we explore our subject, we will discuss these misconceptions in more detail, along with some other common mistakes that developers often make when approaching Java performance analysis and related issues. Still here? Good. Then let’s talk about performance.
     </p>
    </div>
   </section>
   <section data-pdf-bookmark="Java Performance Overview" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-1-SECT-2">
     <h1>
      Java Performance Overview
     </h1>
     <p>
      To understand why Java performance is the way that it is, let’s start by considering a classic quote from James Gosling,
      <a data-primary="performance" data-secondary="overview of Java performance" data-type="indexterm" id="idm139848331782176">
      </a>
      the creator of Java:
     </p>
     <blockquote>
      <p>
       Java is a blue collar language. It’s not PhD thesis material but a language for a job.
      </p>
     </blockquote>
     <p>
      That is, Java has always been an extremely practical language. Its attitude to performance was initially that as long as the environment was
      <em>
       fast enough
      </em>
      , then raw performance could be sacrificed if developer productivity benefited. It was therefore not until relatively recently, with the increasing maturity and sophistication of JVMs such as HotSpot, that the Java environment became suitable for high-performance computing applications.
      <a data-primary="HotSpot JVM" data-type="indexterm" id="idm139848331778896">
      </a>
     </p>
     <p>
      This practicality manifests itself in many ways in the Java platform, but one of the most obvious is the used of
      <em>
       managed subsystems
      </em>
      .
      <a data-primary="managed subsystems" data-type="indexterm" id="idm139848331777264">
      </a>
      The idea is that the developer gives up some aspects of low-level control in exchange for not having to worry about some of the details of the capability under management.
     </p>
     <p>
      The most obvious example of this is, of course, memory management.
      <a data-primary="memory management" data-type="indexterm" id="idm139848331588864">
      </a>
      The JVM provides automatic memory management in the form of a pluggable garbage collection subsystem, so that memory does not have to be manually tracked by the programmer.
     </p>
     <div data-type="note" epub:type="note">
      <h6>
       Note
      </h6>
      <p>
       Managed subsystems occur throughout the JVM and their existence introduces extra complexity into the runtime behavior of JVM applications.
      </p>
     </div>
     <p>
      As we will discuss in the next section, the complex runtime behavior of JVM applications requires us to treat our applications as experiments under test.
This leads us to think about the statistics of observed measurements, and here we make an unfortunate discovery.
     </p>
     <p>
      The observed performance measurements of JVM applications are very often not normally distributed.
      <a data-primary="statistics" data-secondary="naive techniques, inappropriate use for Java/JVM performance" data-type="indexterm" id="idm139848331585264">
      </a>
      This means that elementary statistical techniques (e.g.,
      <em>
       standard deviation
      </em>
      and
      <em>
       variance
      </em>
      ) are ill-suited for handling results from JVM applications.
This is because many basic statistics methods contain an implicit assumption about the normality of results distributions.
     </p>
     <p>
      One way to understand this is that for JVM applications outliers can be very significant—for a low-latency trading application, for example.
This means that sampling of measurements is also problematic, as it can easily miss the exact events that have the most importance.
     </p>
     <p>
      Finally, a word of caution.
It is very easy to be misled by Java performance measurements.
The complexity of the environment means that it is very hard to isolate individual aspects of the system.
     </p>
     <p>
      Measurement also has an overhead, and frequent sampling (or recording every result) can have an observable impact on the performance numbers being recorded.
The nature of Java performance numbers requires a certain amount of statistical sophistication, and naive techniques frequently produce incorrect results when applied to Java/JVM applications.
     </p>
    </div>
   </section>
   <section data-pdf-bookmark="Performance as an Experimental Science" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-1-SECT-3">
     <h1>
      Performance as an Experimental Science
     </h1>
     <p>
      Java/JVM software stacks are, like most modern software systems, very complex.
      <a data-primary="performance" data-secondary="as experimental science" data-type="indexterm" id="idm139848331579104">
      </a>
      In fact, due to the highly optimizing and adaptive nature of the JVM, production systems built on top of the JVM can have some incredibly subtle and intricate performance behavior.
This complexity has been made possible by Moore’s Law and the unprecedented growth in hardware capability that it represents.
     </p>
     <blockquote>
      <p>
       The most amazing achievement of the computer software industry is its continuing cancellation of the steady and staggering gains made by the computer hardware industry.
      </p>
      <p data-type="attribution">
       Henry Petroski
      </p>
     </blockquote>
     <p>
      While some software systems have squandered the historical gains of the industry, the JVM represents something of an engineering triumph.
      <a data-primary="JVMs (Java Virtual Machines)" data-secondary="high-performance nature of" data-type="indexterm" id="idm139848331575360">
      </a>
      Since its inception in the late 1990s the JVM has developed into a very high-performance, general-purpose execution environment that puts those gains to very good use.
The tradeoff, however, is that like any complex, high-performance system, the JVM requires a measure of skill and experience to get the absolute best out of it.
     </p>
     <blockquote>
      <p>
       A measurement not clearly defined is worse than useless.
      </p>
      <p data-type="attribution">
       Eli Goldratt
      </p>
     </blockquote>
     <p>
      JVM performance tuning is therefore a synthesis between technology, methodology, measurable quantities, and tools.
      <a data-primary="JVMs (Java Virtual Machines)" data-secondary="performance tuning, experimental nature of" data-type="indexterm" id="idm139848331571648">
      </a>
      Its aim is to effect measurable outputs in a manner desired by the owners or users of a system.
In other words, performance is an experimental science—it achieves a desired result by:
     </p>
     <ul>
      <li>
       <p>
        Defining the desired outcome
       </p>
      </li>
      <li>
       <p>
        Measuring the existing system
       </p>
      </li>
      <li>
       <p>
        Determining what is to be done to achieve the requirement
       </p>
      </li>
      <li>
       <p>
        Undertaking an improvement exercise
       </p>
      </li>
      <li>
       <p>
        Retesting
       </p>
      </li>
      <li>
       <p>
        Determining whether the goal has been achieved
       </p>
      </li>
     </ul>
     <p>
      The process of defining and determining desired performance outcomes builds a set of quantitative objectives.
It is important to establish what should be measured and record  the objectives, which then form part of the project’s artifacts and deliverables.
From this, we can see that performance analysis is based upon defining, and then achieving, nonfunctional requirements.
     </p>
     <p>
      This process is, as has been previewed, not one of reading chicken entrails or another divination method.
Instead, we rely upon statistics and an appropriate handling of results.
In
      <a data-type="xref" href="ch05.html#pracjavaperf-CHP-5">
       Chapter 5
      </a>
      we will introduce a primer on the basic statistical techniques that are required for accurate handling of data generated from a JVM performance analysis project.
     </p>
     <p>
      For many real-world projects, a more sophisticated understanding of data and statistics will undoubtedly be required.
You are encouraged to view the statistical techniques found in this book as a starting point, rather than a definitive statement.
     </p>
    </div>
   </section>
   <section data-pdf-bookmark="A Taxonomy for Performance" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-1-SECT-4">
     <h1>
      A Taxonomy for Performance
     </h1>
     <p>
      In this section, we introduce some basic performance metrics.
      <a data-primary="performance" data-secondary="taxonomy for" data-type="indexterm" id="ix_perf1tax">
      </a>
      These provide a vocabulary for performance analysis and will allow you to frame the objectives of a tuning project in quantitative terms.
These objectives are the nonfunctional requirements that define performance goals.
One common basic set of performance
      <span class="keep-together">
       metrics is:
      </span>
     </p>
     <ul>
      <li>
       <p>
        Throughput
       </p>
      </li>
      <li>
       <p>
        Latency
       </p>
      </li>
      <li>
       <p>
        Capacity
       </p>
      </li>
      <li>
       <p>
        Utilization
       </p>
      </li>
      <li>
       <p>
        Efficiency
       </p>
      </li>
      <li>
       <p>
        Scalability
       </p>
      </li>
      <li>
       <p>
        Degradation
       </p>
      </li>
     </ul>
     <p>
      We will briefly discuss each in turn.
Note that for most performance projects, not every metric will be optimized simultaneously.
The case of only a few metrics being improved in a single performance iteration is far more common, and this may be as many as can be tuned at once.
In real-world projects, it may well be the case that optimizing one metric comes at the detriment of another metric or group of metrics.
     </p>
     <section data-pdf-bookmark="Throughput" data-type="sect2">
      <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.1">
       <h2>
        Throughput
       </h2>
       <p>
        Throughput is a metric that represents the rate of work a system or subsystem can perform.
        <a data-primary="performance metrics" data-secondary="throughput" data-type="indexterm" id="idm139848332127824">
        </a>
        <a data-primary="throughput" data-secondary="about" data-type="indexterm" id="idm139848332126848">
        </a>
        This is usually expressed as number of units of work in some time period.
For example, we might be interested in how many transactions per second a system can execute.
       </p>
       <p>
        For the throughput number to be meaningful in a real performance exercise, it should include a description of the reference platform it was obtained on.
For example, the hardware spec, OS, and software stack are all relevant to throughput, as is whether the system under test is a single server or a cluster.
In addition, transactions (or units of work) should be the same between tests.
Essentially, we should seek to ensure that the workload for throughput tests is kept consistent between runs.
       </p>
      </div>
     </section>
     <section data-pdf-bookmark="Latency" data-type="sect2">
      <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.2">
       <h2>
        Latency
       </h2>
       <p>
        Performance metrics are sometimes explained via metaphors that evoke plumbing.
If a water pipe can produce 100 liters per second, then the volume produced in 1 second (100 liters) is the throughput.
        <a data-primary="latency" data-secondary="about" data-type="indexterm" id="idm139848332122608">
        </a>
        <a data-primary="performance metrics" data-secondary="latency" data-type="indexterm" id="idm139848332121632">
        </a>
        In this metaphor, the latency is effectively the length of the pipe.
That is, it’s the time taken to process a single transaction and see a result at the other end of the pipe.
       </p>
       <p>
        It is normally quoted as an end-to-end time.
It is dependent on workload, so a common approach is to produce a graph showing latency as a function of increasing workload.
We will see an example of this type of graph in
        <a data-type="xref" href="#pracjavaperf-CHP-1-SECT-5">
         “Reading Performance Graphs”
        </a>
        .
       </p>
      </div>
     </section>
     <section data-pdf-bookmark="Capacity" data-type="sect2">
      <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.3">
       <h2>
        Capacity
       </h2>
       <p>
        The capacity is the amount of work parallelism a system possesses—that is, the
number of units of work (e.g., transactions) that can be simultaneously ongoing in the
system.
        <a data-primary="performance metrics" data-secondary="capacity" data-type="indexterm" id="idm139848332116832">
        </a>
        <a data-primary="capacity" data-type="indexterm" id="idm139848332115856">
        </a>
       </p>
       <p>
        Capacity is obviously related to throughput, and we should expect that as the
concurrent load on a system increases, throughput (and latency) will be
affected. For this reason, capacity is usually quoted as the processing available at
a given value of latency or throughput.
       </p>
      </div>
     </section>
     <section data-pdf-bookmark="Utilization" data-type="sect2">
      <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.4">
       <h2>
        Utilization
       </h2>
       <p>
        One of the most common performance analysis tasks is to achieve efficient use of a system’s resources.
        <a data-primary="CPU utilization" data-type="indexterm" id="idm139848332112512">
        </a>
        Ideally, CPUs should be used for handling units of work, rather than being idle (or spending time handling OS or other housekeeping tasks).
        <a data-primary="performance metrics" data-secondary="utilization" data-type="indexterm" id="idm139848332111520">
        </a>
        <a data-primary="utilization" data-secondary="about" data-type="indexterm" id="idm139848332110576">
        </a>
       </p>
       <p>
        Depending on the workload, there can be a huge difference between the utilization levels of different resources. For example, a computation-intensive workload (such as graphics processing or encryption) may be running at close to 100% CPU but only
be using a small percentage of available memory.
       </p>
      </div>
     </section>
     <section data-pdf-bookmark="Efficiency" data-type="sect2">
      <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.5">
       <h2>
        Efficiency
       </h2>
       <p>
        Dividing the throughput of a system by the utilized resources gives a measure of the overall efficiency of the system.
        <a data-primary="performance metrics" data-secondary="efficiency" data-type="indexterm" id="idm139848332106928">
        </a>
        <a data-primary="efficiency" data-type="indexterm" id="idm139848332105952">
        </a>
        Intuitively, this makes sense, as requiring more resources to produce the same throughput is one useful definition of being less efficient.
       </p>
       <p>
        It is also possible, when one is dealing with larger systems, to use a form of cost accounting to measure efficiency. If solution A has a total dollar cost of ownership (TCO) twice that of solution B for the same throughput then it is, clearly, half as efficient.
       </p>
      </div>
     </section>
     <section data-pdf-bookmark="Scalability" data-type="sect2">
      <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.6">
       <h2>
        Scalability
       </h2>
       <p>
        The throughout or capacity of a system depends upon the resources available for processing.
        <a data-primary="scalability" data-secondary="about" data-type="indexterm" id="idm139848331774176">
        </a>
        <a data-primary="performance metrics" data-secondary="scalability" data-type="indexterm" id="idm139848331773200">
        </a>
        The change in throughput as resources are added is one measure of the scalability of a system or application. The holy grail of system scalability is to have throughput change exactly in step with resources.
       </p>
       <p>
        Consider a system based on a cluster of servers. If the cluster is expanded, for example, by doubling in size, then what throughput can be achieved? If the new cluster can handle twice the volume of transactions, then the system is exhibiting  “perfect linear scaling.” This is very difficult to achieve in practice, especially over a  wide range of possible loads.
       </p>
       <p>
        System scalability is dependent upon a number of factors, and is not normally a simple constant factor. It is very common for a system to scale close to linearly for some range of resources, but then at higher loads to encounter some limitation that prevents perfect scaling.
       </p>
      </div>
     </section>
     <section data-pdf-bookmark="Degradation" data-type="sect2">
      <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.7">
       <h2>
        Degradation
       </h2>
       <p>
        If we increase the load on a system, either by increasing the number of requests (or
clients) or by increasing the speed requests arrive at, then we may see a change in
the observed latency and/or throughput.
        <a data-primary="performance metrics" data-secondary="degradation" data-type="indexterm" id="idm139848331768512">
        </a>
        <a data-primary="degradation" data-secondary="about" data-type="indexterm" id="idm139848331767536">
        </a>
       </p>
       <p>
        Note that this change is dependent on utilization. If the system is underutilized,
then there should be some slack before observables change, but if resources are fully
utilized then we would expect to see throughput stop increasing, or latency increase.
These changes are usually called the degradation of the system under additional load.
       </p>
      </div>
     </section>
     <section data-pdf-bookmark="Connections Between the Observables" data-type="sect2">
      <div class="sect2" id="pracjavaperf-CHP-1-SECT-4.8">
       <h2>
        Connections Between the Observables
       </h2>
       <p>
        The behavior of the various performance observables is usually connected in some manner.
        <a data-primary="performance" data-secondary="connections between observables" data-type="indexterm" id="idm139848331763664">
        </a>
        The details of this connection will depend upon whether the system is running at peak utility. For example, in general, the utilization will change as the load on a system increases.
        <a data-primary="utilization" data-secondary="connections with other performance observables" data-type="indexterm" id="idm139848331762304">
        </a>
        However, if the system is underutilized, then increasing load may not appreciably increase utilization. Conversely, if the system is already stressed, then the effect of increasing load may be felt in another observable.
       </p>
       <p>
        As another example, scalability and degradation both represent the change in behavior of a system as more load is added.
        <a data-primary="scalability" data-secondary="connections with other performance observables" data-type="indexterm" id="idm139848331760496">
        </a>
        <a data-primary="degradation" data-secondary="connections with other performance observables" data-type="indexterm" id="idm139848331759488">
        </a>
        For scalability, as the load is increased, so are available resources, and the central question is whether the system can make use of them. On the other hand, if load is added but additional resources are not provided, degradation of some performance observable (e.g., latency) is the expected outcome.
       </p>
       <div data-type="note" epub:type="note">
        <h6>
         Note
        </h6>
        <p>
         In rare cases, additional load can cause counterintuitive results. For example, if the change in load causes some part of the system to switch to a more resource-intensive but higher-performance mode, then the overall effect can be to reduce latency, even though more requests are being received.
        </p>
       </div>
       <p>
        To take one example, in
        <a data-type="xref" href="ch09.html#pracjavaperf-CHP-9">
         Chapter 9
        </a>
        we will discuss HotSpot’s JIT compiler in detail. To be considered eligible for JIT compilation, a method has to be executed in interpreted mode “sufficiently frequently.” So it is possible at low load to have key methods stuck in interpreted mode, but for those to become eligible for compilation at higher loads due to increased calling frequency on the methods. This causes later calls to the same method to run much, much faster than earlier executions.
       </p>
       <p>
        Different workloads can have very different characteristics.
        <a data-primary="latency" data-secondary="connections with other performance observables" data-type="indexterm" id="idm139848331754528">
        </a>
        For example, a trade on
the financial markets, viewed end to end, may have an execution time (i.e., latency)
of hours or even days. However, millions of them may be in progress at a major
bank at any given time. Thus, the capacity of the system is very large, but the
latency is also large.
       </p>
       <p>
        However, let’s consider only a single subsystem within the bank. The matching of a
buyer and a seller (which is essentially the parties agreeing on a price) is known
as
        <em>
         order matching
        </em>
        . This individual subsystem may have only hundreds of pending
orders at any given time, but the latency from order acceptance to completed match
may be as little as 1 millisecond (or even less in the case of “low-latency” trading).
       </p>
       <p>
        In this section we have met the most frequently encountered performance observables.
Occasionally slightly different definitions, or even different metrics, are used, but
in most cases these will be the basic system numbers that will normally be used
to guide performance tuning, and act as a taxonomy for discussing the performance of
systems of interest.
        <a data-primary="performance" data-secondary="taxonomy for" data-startref="ix_perf1tax" data-type="indexterm" id="idm139848331751056">
        </a>
       </p>
      </div>
     </section>
    </div>
   </section>
   <section data-pdf-bookmark="Reading Performance Graphs" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-1-SECT-5">
     <h1>
      Reading Performance Graphs
     </h1>
     <p>
      To conclude this chapter, let’s look at some common patterns of behavior
that occur in performance tests.
      <a data-primary="performance" data-secondary="reading performance graphs" data-type="indexterm" id="idm139848331747728">
      </a>
      We will explore these by looking at graphs of real
observables, and we will encounter many other examples of graphs of our data as we
proceed.
     </p>
     <p>
      The graph in
      <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-1">
       Figure 1-1
      </a>
      shows sudden, unexpected degradation of performance (in this case, latency) under increasing load—commonly called a
      <em>
       performance elbow
      </em>
      .
      <a data-primary="performance elbow" data-type="indexterm" id="idm139848331744624">
      </a>
     </p>
     <figure class="width_set_50">
      <div class="figure" id="pracjavaperf-CHP-1-FIG-1">
       <img alt="opjv 0101" height="897" src="library/view/optimizing-java/9781492039259/assets/opjv_0101.png" width="941"/>
       <h6>
        <span class="label">
         Figure 1-1.
        </span>
        A performance elbow
       </h6>
      </div>
     </figure>
     <p>
      By contrast,
      <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-2">
       Figure 1-2
      </a>
      shows the much happier case of
throughput scaling almost linearly as machines are added to a cluster.
      <a data-primary="linear scaling" data-type="indexterm" id="idm139848331740224">
      </a>
      This is close to ideal behavior, and is only likely to be achieved in extremely favorable circumstances—e.g., scaling a stateless  protocol with no need for session affinity with a single server.
     </p>
     <figure class="width_set_50">
      <div class="figure" id="pracjavaperf-CHP-1-FIG-2">
       <img alt="opjv 0102" height="954" src="library/view/optimizing-java/9781492039259/assets/opjv_0102.png" width="954"/>
       <h6>
        <span class="label">
         Figure 1-2.
        </span>
        Near-linear scaling
       </h6>
      </div>
     </figure>
     <p>
      In
      <a data-type="xref" href="ch12.html#pracjavaperf-CHP-12">
       Chapter 12
      </a>
      we will meet Amdahl’s Law,
      <a data-primary="Amdahl's Law" data-type="indexterm" id="idm139848331735680">
      </a>
      <a data-primary="scalability" data-secondary="Amdahl's Law" data-type="indexterm" id="idm139848331735008">
      </a>
      named for the famous computer scientist (and “father of the mainframe”) Gene Amdahl of IBM.
      <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-3">
       Figure 1-3
      </a>
      shows a graphical representation of his fundamental constraint on scalability; it shows the maximum possible speedup as a function of the number of processors devoted to the task.
     </p>
     <figure>
      <div class="figure" id="pracjavaperf-CHP-1-FIG-3">
       <img alt="opjv 0103" height="900" src="library/view/optimizing-java/9781492039259/assets/opjv_0103.png" width="1440"/>
       <h6>
        <span class="label">
         Figure 1-3.
        </span>
        Amdahl’s Law
       </h6>
      </div>
     </figure>
     <p>
      We display three cases: where the underlying task is 75%, 90%, and 95% parallelizable.
This clearly shows that whenever the workload has any piece at all that must be performed serially, linear scalability is impossible, and there are strict limits on how much scalability can be achieved.
This justifies the commentary around
      <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-2">
       Figure 1-2
      </a>
      —even in the best cases linear scalability is all but impossible to achieve.
     </p>
     <p>
      The limits imposed by Amdahl’s Law are surprisingly restrictive.
Note in particular that the  x-axis of the graph is logarithmic, and so even with an algorithm that is (only) 5% serial, 32 processors are needed for a factor-of-12 speedup.
Even worse, no matter how many cores are used, the maximum speedup is only a factor of 20 for that algorithm.
In practice, many algorithms are far more than 5% serial, and so have a more constrained maximum possible speedup.
      <a data-primary="memory management" data-secondary="healthy memory usage and allocation rate" data-type="indexterm" id="idm139848331861952">
      </a>
     </p>
     <p>
      As we will see in
      <a data-type="xref" href="ch06.html#pracjavaperf-CHP-6">
       Chapter 6
      </a>
      , the underlying technology in the JVM’s garbage collection subsystem naturally gives rise to a “sawtooth” pattern of memory used for healthy applications that aren’t under stress.
We can see an example in
      <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-4">
       Figure 1-4
      </a>
      .
     </p>
     <figure>
      <div class="figure" id="pracjavaperf-CHP-1-FIG-4">
       <img alt="opjv 0104" height="890" src="library/view/optimizing-java/9781492039259/assets/opjv_0104.png" width="1134"/>
       <h6>
        <span class="label">
         Figure 1-4.
        </span>
        Healthy memory usage
       </h6>
      </div>
     </figure>
     <p class="pagebreak-before">
      In
      <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-5">
       Figure 1-5
      </a>
      , we show another memory graph that can be of great importance when performance tuning an application’s memory allocation rate. This short example shows a sample application (calculating Fibonnaci numbers). It clearly displays a sharp drop in the allocation rate at around the 90 second mark.
     </p>
     <p>
      Other graphs from the same tool (jClarity Censum) show that the
application starts to suffer from major garbage collection problems at
this time, and so the application is unable to allocate sufficient
memory due to CPU contention from the garbage collection threads.
     </p>
     <p>
      We can also spot that the allocation subsystem is running hot—allocating over 4 GB per second. This is well above the recommended
maximum capacity of most modern systems (including server class
hardware). We will have much more to say about the subject of
allocation when we discuss garbage collection in
      <a data-type="xref" href="ch06.html#pracjavaperf-CHP-6">
       Chapter 6
      </a>
      .
     </p>
     <figure>
      <div class="figure" id="pracjavaperf-CHP-1-FIG-5">
       <img alt="opjv 0105" height="758" src="library/view/optimizing-java/9781492039259/assets/opjv_0105.png" width="1133"/>
       <h6>
        <span class="label">
         Figure 1-5.
        </span>
        Sample problematic allocation rate
       </h6>
      </div>
     </figure>
     <p>
      In the case where a system has a resource leak,
      <a data-primary="resource leaks" data-type="indexterm" id="idm139848331850192">
      </a>
      it is far more common for it to
manifest in a manner like that shown in
      <a data-type="xref" href="#pracjavaperf-CHP-1-FIG-6">
       Figure 1-6
      </a>
      ,
where an observable (in this case latency) slowly degrades as the load is ramped
up, before hitting an inflection point where the system rapidly degrades.
      <a data-primary="latency" data-secondary="degradation with system resource leak" data-type="indexterm" id="idm139848331848320">
      </a>
     </p>
     <figure class="width_set_50">
      <div class="figure" id="pracjavaperf-CHP-1-FIG-6">
       <img alt="opjv 0106" height="1051" src="library/view/optimizing-java/9781492039259/assets/opjv_0106.png" width="1175"/>
       <h6>
        <span class="label">
         Figure 1-6.
        </span>
        Degrading latency under higher load
       </h6>
      </div>
     </figure>
    </div>
   </section>
   <section data-pdf-bookmark="Summary" data-type="sect1">
    <div class="sect1" id="idm139848331749216">
     <h1>
      Summary
     </h1>
     <p>
      In this chapter we have started to discuss what Java performance is and is not. We have introduced the fundamental topics of empirical science and measurement, and the basic vocabulary and observables that a good performance exercise will use. Finally, we have introduced some common cases that are often seen within the results obtained from performance tests. Let’s move on and begin our discussion of some of the major aspects of the JVM, and set the scene for understanding what makes JVM-based performance optimization a particularly complex problem.
      <a data-primary="performance" data-startref="ix_perf1" data-type="indexterm" id="idm139848331843264">
      </a>
     </p>
    </div>
   </section>
  </div>
 </section>
</div>
</div>
<div class="page"><div id="sbo-rt-content">
 <section data-pdf-bookmark="Chapter 2. Overview of the JVM" data-type="chapter" epub:type="chapter">
  <div class="chapter" id="pracjavaperf-CHP-2">
   <h1>
    <span class="label">
     Chapter 2.
    </span>
    Overview of the JVM
   </h1>
   <p id="pracjavaperf-CHP-2-SECT-1">
    There is no doubt that Java is one of the largest technology platforms on the planet, boasting roughly 9–10 million developers (according to Oracle).
By design, many developers do not need to know about the low-level intricacies of the platform they work with.
    <a data-primary="JVMs (Java Virtual Machines)" data-secondary="overview" data-type="indexterm" id="ix_JVMovr">
    </a>
    This leads to a situation where developers only meet these aspects when a customer complains about performance for the first time.
    <a data-primary="performance" data-secondary="understanding the JVM" data-type="indexterm" id="ix_perfundJVM">
    </a>
   </p>
   <p>
    For developers interested in performance, however, it is important to understand the basics of the JVM technology stack. Understanding JVM technology enables developers to write better software and provides the theoretical background required for investigating performance-related issues.
   </p>
   <p>
    This chapter introduces how the JVM executes Java in order to provide a basis for deeper exploration of these topics later in the book. In particular,
    <a data-type="xref" href="ch09.html#pracjavaperf-CHP-9">
     Chapter 9
    </a>
    has an in-depth treatment of bytecode. One strategy for the reader could be to read this chapter now, and then reread it in conjunction with
    <a data-type="xref" href="ch09.html#pracjavaperf-CHP-9">
     Chapter 9
    </a>
    , once some of the other topics have been understood.
   </p>
   <section data-pdf-bookmark="Interpreting and Classloading" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-2-SECT-2">
     <h1>
      Interpreting and Classloading
     </h1>
     <p>
      According to the specification that defines the Java Virtual Machine (usually called the VM Spec), the JVM is a stack-based interpreted machine.
      <a data-primary="JVMs (Java Virtual Machines)" data-secondary="overview" data-tertiary="interpreting and classloading" data-type="indexterm" id="idm139848331831584">
      </a>
      This means that rather than having registers (like a physical hardware CPU), it uses an execution stack of partial results and performs calculations by operating on the top value (or values) of that stack.
      <a data-primary="stack-based interpreted machine (JVM)" data-type="indexterm" id="idm139848331829904">
      </a>
     </p>
     <p>
      The basic behavior of the JVM interpreter can be thought of as essentially “a
      <code>
       switch
      </code>
      inside a
      <code>
       while
      </code>
      loop”—processing each opcode of the program independently of the last, using the evaluation stack to hold intermediate values.
      <a data-primary="interpreters" data-type="indexterm" id="idm139848331827824">
      </a>
     </p>
     <div data-type="note" epub:type="note">
      <h6>
       Note
      </h6>
      <p>
       As we will see when we delve into the internals of the Oracle/OpenJDK VM (HotSpot), the situation for real production-grade Java interpreters can be more complex, but
       <em>
        switch-inside-while
       </em>
       is an acceptable mental model for the moment.
       <a data-primary="Oracle/Open JDK" data-secondary="HotSpot VM" data-type="indexterm" id="idm139848331825552">
       </a>
      </p>
     </div>
     <p>
      When we launch our application using the
      <code>
       java HelloWorld
      </code>
      command, the operating system starts the virtual machine process (the
      <code>
       java
      </code>
      binary). This sets up the Java virtual environment and initializes the stack machine that will actually execute the user code in the
      <em>
       HelloWorld
      </em>
      class file.
     </p>
     <p>
      The entry point into the application will be the
      <code>
       main()
      </code>
      method of
      <em>
       HelloWorld.class
      </em>
      . In order to hand over control to this class, it must be loaded by the virtual machine before execution can begin.
     </p>
     <p>
      To achieve this, the Java classloading mechanism is used.
      <a data-primary="classloading" data-type="indexterm" id="idm139848331820688">
      </a>
      When a new Java process is initializing, a chain of classloaders is used. The initial loader is known as the Bootstrap classloader and contains classes in the core Java runtime.
      <a data-primary="Bootstrap classloader" data-type="indexterm" id="idm139848331819664">
      </a>
      In versions of Java up to and including 8, these are loaded from
      <em>
       rt.jar
      </em>
      . In version 9 and later, the runtime has been modularised and the concepts of classloading are somewhat different.
     </p>
     <p>
      The main point of the Bootstrap classloader is to get a minimal set of classes (which includes essentials such as
      <code>
       java.lang.Object
      </code>
      ,
      <code>
       Class
      </code>
      , and
      <code>
       Classloader
      </code>
      ) loaded to allow other classloaders to bring up the rest of the system.
      <a data-primary="classloaders" data-type="indexterm" id="idm139848331816416">
      </a>
     </p>
     <div data-type="note" epub:type="note">
      <h6>
       Note
      </h6>
      <p>
       Java models classloaders as objects within its own runtime and type system, so there needs to be some way to bring an initial set of classes into existence. Otherwise, there would be a circularity problem in defining what a classloader is.
      </p>
     </div>
     <p>
      The Extension classloader is created next; it defines its parent to be the Bootstrap classloader and will delegate to its parent if needed.
      <a data-primary="Extension classloader" data-type="indexterm" id="idm139848331813776">
      </a>
      Extensions are not widely used, but can supply overrides and native code for specific operating systems and platforms. Notably, the Nashorn JavaScript runtime introduced in Java 8 is loaded by the Extension loader.
     </p>
     <p>
      Finally, the Application classloader is created; it is responsible for loading in user classes from the defined classpath.
      <a data-primary="Application classloader" data-type="indexterm" id="idm139848331812192">
      </a>
      Some texts unfortunately refer to this as the “System” classloader. This term should be avoided, for the simple reason that it doesn’t load the system classes (the Bootstrap classloader does). The Application classloader is encountered extremely frequently, and it has the Extension loader as its parent.
     </p>
     <p>
      Java loads in dependencies on new classes when they are first encountered during the execution of the program. If a classloader fails to find a class, the behavior is usually to delegate the lookup to the parent. If the chain of lookups reaches the Bootstrap classloader and it isn’t found, a
      <code>
       ClassNotFoundException
      </code>
      will be thrown.
      <a data-primary="ClassNotFoundException" data-type="indexterm" id="idm139848331809936">
      </a>
      It is important that developers use a build process that effectively compiles with the exact same classpath that will be used in production, as this helps to mitigate this potential issue.
     </p>
     <p>
      Under normal circumstances Java only loads a class once and a
      <code>
       Class
      </code>
      object is created to represent the class in the runtime environment. However, it is important to realize that the same class can potentially be loaded twice by different classloaders. As a result, a class in the system is identified by the classloader used to load it as well as the fully qualified class name (which includes the package name).
     </p>
    </div>
   </section>
   <section data-pdf-bookmark="Executing Bytecode" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-2-SECT-3">
     <h1>
      Executing Bytecode
     </h1>
     <p>
      It is important to appreciate that Java source code goes through a significant number of transformations before execution.
      <a data-primary="JVMs (Java Virtual Machines)" data-secondary="overview" data-tertiary="executing byte code" data-type="indexterm" id="idm139848331805264">
      </a>
      <a data-primary="javac" data-type="indexterm" id="idm139848331804000">
      </a>
      <a data-primary="compilation" data-secondary="Java code" data-type="indexterm" id="idm139848331678080">
      </a>
      The first is the compilation step using the Java compiler
      <code>
       javac
      </code>
      , often invoked as part of a larger build process.
     </p>
     <p>
      The job of
      <code>
       javac
      </code>
      is to convert Java code into
      <em>
       .class
      </em>
      files that contain bytecode.
      <a data-primary="bytecode" data-secondary="compilation of Java class files to" data-type="indexterm" id="idm139848331675056">
      </a>
      <a data-primary=".class files" data-primary-sortas="class files" data-secondary="compilation" data-type="indexterm" id="idm139848331674016">
      </a>
      It achieves this by doing a fairly straightforward translation of the Java source code, as shown in
      <a data-type="xref" href="#pracjavaperf-CHP-2-FIG-1">
       Figure 2-1
      </a>
      . Very  few optimizations are done during compilation by
      <code>
       javac
      </code>
      , and the resulting bytecode is still quite readable and recognizable as Java code when viewed in a disassembly tool, such as the standard
      <code>
       javap
      </code>
      .
     </p>
     <figure>
      <div class="figure" id="pracjavaperf-CHP-2-FIG-1">
       <img alt="opjv 0201" height="830" src="library/view/optimizing-java/9781492039259/assets/opjv_0201.png" width="1565"/>
       <h6>
        <span class="label">
         Figure 2-1.
        </span>
        Java class file compilation
       </h6>
      </div>
     </figure>
     <p>
      Bytecode is an intermediate representation that is not tied to a specific machine architecture. Decoupling from the machine architecture provides portability, meaning already developed (or compiled) software can run on any platform supported by the JVM and provides an abstraction from the Java language. This provides our first important insight into the way the JVM executes code.
     </p>
     <div data-type="note" epub:type="note">
      <h6>
       Note
      </h6>
      <p>
       The Java language and the Java Virtual Machine are now to a degree independent, and so the J in JVM is potentially a little misleading, as the JVM can execute any JVM language that can produce a valid class file. In fact,
       <a data-type="xref" href="#pracjavaperf-CHP-2-FIG-1">
        Figure 2-1
       </a>
       could just as easily show the Scala compiler
       <code>
        scalac
       </code>
       generating bytecode for execution on the JVM.
      </p>
     </div>
     <p>
      Regardless of the source code compiler used, the resulting class file has a very well-defined structure specified by the VM specification (
      <a data-type="xref" href="#anatomy-of-class-file">
       Table 2-1
      </a>
      ). Any class that is loaded by the JVM will be verified to conform to the expected format before being allowed to run.
      <a data-primary=".class files" data-primary-sortas="class files" data-secondary="anatomy of" data-type="indexterm" id="idm139848331663728">
      </a>
     </p>
     <table id="anatomy-of-class-file">
      <caption>
       <span class="label">
        Table 2-1.
       </span>
       Anatomy of a class file
      </caption>
      <thead>
       <tr>
        <th>
         Component
        </th>
        <th>
         Description
        </th>
       </tr>
      </thead>
      <tbody>
       <tr>
        <td>
         <p>
          Magic number
         </p>
        </td>
        <td>
         <p>
          <code>
           0xCAFEBABE
          </code>
         </p>
        </td>
       </tr>
       <tr>
        <td>
         <p>
          Version of class file format
         </p>
        </td>
        <td>
         <p>
          The minor and major versions of the class file
         </p>
        </td>
       </tr>
       <tr>
        <td>
         <p>
          Constant pool
         </p>
        </td>
        <td>
         <p>
          The pool of constants for the class
         </p>
        </td>
       </tr>
       <tr>
        <td>
         <p>
          Access flags
         </p>
        </td>
        <td>
         <p>
          Whether the class is abstract, static, and so on
         </p>
        </td>
       </tr>
       <tr>
        <td>
         <p>
          This class
         </p>
        </td>
        <td>
         <p>
          The name of the current class
         </p>
        </td>
       </tr>
       <tr>
        <td>
         <p>
          Superclass
         </p>
        </td>
        <td>
         <p>
          The name of the superclass
         </p>
        </td>
       </tr>
       <tr>
        <td>
         <p>
          Interfaces
         </p>
        </td>
        <td>
         <p>
          Any interfaces in the class
         </p>
        </td>
       </tr>
       <tr>
        <td>
         <p>
          Fields
         </p>
        </td>
        <td>
         <p>
          Any fields in the class
         </p>
        </td>
       </tr>
       <tr>
        <td>
         <p>
          Methods
         </p>
        </td>
        <td>
         <p>
          Any methods in the class
         </p>
        </td>
       </tr>
       <tr>
        <td>
         <p>
          Attributes
         </p>
        </td>
        <td>
         <p>
          Any attributes of the class (e.g., name of the source file, etc.)
         </p>
        </td>
       </tr>
      </tbody>
     </table>
     <p>
      Every class file starts with the magic number
      <code>
       0xCAFEBABE
      </code>
      , the first 4 bytes in hexadecimal serving to denote conformance to the class file format.
      <a data-primary="0xCAFEBABE magic number" data-type="indexterm" id="idm139848331641664">
      </a>
      <a data-primary="magic numbers" data-type="indexterm" id="idm139848331640960">
      </a>
      The following 4 bytes represent the minor and major versions used to compile the class file, and these are checked to ensure that the target JVM is not of a lower version than the one used to compile the class file. The major and minor version are checked by the classloader to ensure compatibility; if these are not compatible an
      <code>
       UnsupportedClassVersionError
      </code>
      will be thrown at runtime, indicating the runtime is a lower version than the compiled class file.
     </p>
     <div data-type="note" epub:type="note">
      <h6>
       Note
      </h6>
      <p>
       Magic numbers provide a way for Unix environments to identify the type of a file (whereas Windows will typically use the file extension). For this reason, they are difficult to change once decided upon. Unfortunately, this means that Java is stuck using the rather embarrassing and sexist
       <code>
        0xCAFEBABE
       </code>
       for the foreseeable future, although Java 9 introduces the magic number
       <code>
        0xCAFEDADA
       </code>
       for module files.
      </p>
     </div>
     <p>
      The constant pool holds constant values in code: for example, names of classes, interfaces, and fields.
      <a data-primary="constant pool" data-type="indexterm" id="idm139848331636464">
      </a>
      When the JVM executes code, the constant pool table is used to refer to values rather than having to rely on the layout of memory at runtime.
     </p>
     <p>
      Access flags are used to determine the modifiers applied to the class.
      <a data-primary="access flags" data-type="indexterm" id="idm139848331635088">
      </a>
      The first part of the flag identifies general properties, such as whether a class is public, followed by whether it is final and
cannot be subclassed. The flag also determines whether the class file represents an interface or an abstract class. The final part of the flag indicates whether the class file represents a synthetic class that is not present in source code, an annotation type, or an enum.
     </p>
     <p>
      The
      <code>
       this
      </code>
      class, superclass, and interface entries are indexes into the constant pool to identify the type hierarchy belonging to the class. Fields and methods define a signature-like structure, including the modifiers that apply to the field or method. A set of attributes is then used to represent structured items for more complicated and non-fixed-size structures. For example, methods make use of the
      <code>
       Code
      </code>
      attribute to represent the bytecode associated with that particular method.
      <a data-primary=".class files" data-primary-sortas="class files" data-secondary="mnemonic for structure" data-type="indexterm" id="idm139848331632096">
      </a>
     </p>
     <p>
      <a data-type="xref" href="#pracjavaperf-CHP-2-FIG-2">
       Figure 2-2
      </a>
      provides a mnemonic for remembering the structure.
     </p>
     <figure>
      <div class="figure" id="pracjavaperf-CHP-2-FIG-2">
       <img alt="opjv 0202" height="708" src="library/view/optimizing-java/9781492039259/assets/opjv_0202.png" width="1440"/>
       <h6>
        <span class="label">
         Figure 2-2.
        </span>
        Mnemonic for class file structure
       </h6>
      </div>
     </figure>
     <p>
      In this very simple code example, it is possible to observe the effect of running
      <code>
       javac
      </code>
      :
     </p>
     <pre data-code-language="java" data-type="programlisting"><code class="kd">public</code> <code class="kd">class</code> <code class="nc">HelloWorld</code> <code class="o">{</code>
    <code class="kd">public</code> <code class="kd">static</code> <code class="kt">void</code> <code class="nf">main</code><code class="o">(</code><code class="n">String</code><code class="o">[]</code> <code class="n">args</code><code class="o">)</code> <code class="o">{</code>
        <code class="k">for</code> <code class="o">(</code><code class="kt">int</code> <code class="n">i</code> <code class="o">=</code> <code class="mi">0</code><code class="o">;</code> <code class="n">i</code> <code class="o">&lt;</code> <code class="mi">10</code><code class="o">;</code> <code class="n">i</code><code class="o">++)</code> <code class="o">{</code>
            <code class="n">System</code><code class="o">.</code><code class="na">out</code><code class="o">.</code><code class="na">println</code><code class="o">(</code><code class="s">"Hello World"</code><code class="o">);</code>
        <code class="o">}</code>
    <code class="o">}</code>
<code class="o">}</code></pre>
     <p>
      Java ships with a class file disassembler called
      <code>
       javap
      </code>
      , allowing inspection of
      <em>
       .class
      </em>
      files.
      <a data-primary=".class files" data-primary-sortas="class files" data-secondary="javap disassembler" data-type="indexterm" id="idm139848326649056">
      </a>
      <a data-primary="javap (class file disassembler)" data-type="indexterm" id="idm139848329804784">
      </a>
      Taking the
      <em>
       HelloWorld
      </em>
      class file and running
      <code>
       javap -c HelloWorld
      </code>
      gives the following output:
     </p>
     <pre data-code-language="java" data-type="programlisting"><code class="kd">public</code> <code class="kd">class</code> <code class="nc">HelloWorld</code> <code class="o">{</code>
  <code class="kd">public</code> <code class="nf">HelloWorld</code><code class="o">();</code>
    <code class="nl">Code:</code>
       <code class="mi">0</code><code class="o">:</code> <code class="n">aload_0</code>
       <code class="mi">1</code><code class="o">:</code> <code class="n">invokespecial</code> <code class="err">#</code><code class="mi">1</code>    <code class="c1">// Method java/lang/Object."&lt;init&gt;":()V</code>
       <code class="mi">4</code><code class="o">:</code> <code class="k">return</code>

  <code class="kd">public</code> <code class="kd">static</code> <code class="kt">void</code> <code class="nf">main</code><code class="o">(</code><code class="n">java</code><code class="o">.</code><code class="na">lang</code><code class="o">.</code><code class="na">String</code><code class="o">[]);</code>
    <code class="nl">Code:</code>
       <code class="mi">0</code><code class="o">:</code> <code class="n">iconst_0</code>
       <code class="mi">1</code><code class="o">:</code> <code class="n">istore_1</code>
       <code class="mi">2</code><code class="o">:</code> <code class="n">iload_1</code>
       <code class="mi">3</code><code class="o">:</code> <code class="n">bipush</code>        <code class="mi">10</code>
       <code class="mi">5</code><code class="o">:</code> <code class="n">if_icmpge</code>     <code class="mi">22</code>
       <code class="mi">8</code><code class="o">:</code> <code class="n">getstatic</code>     <code class="err">#</code><code class="mi">2</code>    <code class="c1">// Field java/lang/System.out ...</code>
      <code class="mi">11</code><code class="o">:</code> <code class="n">ldc</code>           <code class="err">#</code><code class="mi">3</code>    <code class="c1">// String Hello World</code>
      <code class="mi">13</code><code class="o">:</code> <code class="n">invokevirtual</code> <code class="err">#</code><code class="mi">4</code>    <code class="c1">// Method java/io/PrintStream.println ...</code>
      <code class="mi">16</code><code class="o">:</code> <code class="n">iinc</code>          <code class="mi">1</code><code class="o">,</code> <code class="mi">1</code>
      <code class="mi">19</code><code class="o">:</code> <code class="k">goto</code>          <code class="mi">2</code>
      <code class="mi">22</code><code class="o">:</code> <code class="k">return</code>
<code class="o">}</code></pre>
     <p>
      This layout describes
      <a data-primary="bytecode" data-secondary="for HelloWorld.class file" data-type="indexterm" id="idm139848329681072">
      </a>
      the bytecode for the file
      <em>
       HelloWorld.class
      </em>
      . For more detail
      <code>
       javap
      </code>
      also has a
      <code>
       -v
      </code>
      option that provides the full class file header information and constant pool details. The class file contains two methods, although only the single
      <code>
       main()
      </code>
      method was supplied in the source file; this is the result of
      <code>
       javac
      </code>
      automatically adding a default constructor to the class.
     </p>
     <p>
      The first instruction executed in the constructor is
      <code>
       aload_0
      </code>
      , which places the
      <code>
       this
      </code>
      reference onto the first position in the stack. The
      <code>
       invokespecial
      </code>
      command is then called, which invokes an instance method that has specific handling for calling superconstructors and creating objects. In the default constructor, the invoke matches the default constructor for
      <code>
       Object
      </code>
      , as an override was not supplied.
     </p>
     <div data-type="note" epub:type="note">
      <h6>
       Note
      </h6>
      <p>
       Opcodes in the JVM are concise and represent the type, the operation, and the interaction between local variables, the constant pool, and the stack.
      </p>
     </div>
     <p>
      Moving on to the
      <code>
       main()
      </code>
      method,
      <code>
       iconst_0
      </code>
      pushes the integer constant
      <code>
       0
      </code>
      onto the evaluation stack.
      <code>
       istore_1
      </code>
      stores this constant value into the local variable at offset 1 (represented as
      <code>
       i
      </code>
      in the loop).
      <a data-primary="variables" data-secondary="local variable offsets" data-type="indexterm" id="idm139848329569600">
      </a>
      <a data-primary="local variables" data-secondary="offsets" data-type="indexterm" id="idm139848329568592">
      </a>
      <a data-primary="offsets (variable)" data-type="indexterm" id="idm139848329567648">
      </a>
      Local variable offsets start at 0, but for instance methods, the 0th entry is always
      <code>
       this
      </code>
      . The variable at offset 1 is then loaded back onto the stack and the constant
      <code>
       10
      </code>
      is pushed for comparison using
      <code>
       if_icmpge
      </code>
      (“if integer compare greater or equal”). The test only succeeds if the current integer is &gt;= 10.
     </p>
     <p>
      For the first few iterations, this comparison test fails and so we continue to instruction 8. Here the static method from
      <code>
       System.out
      </code>
      is resolved, followed by the loading of the “Hello World” string from the constant pool. The next invoke,
      <code>
       invokevirtual
      </code>
      , invokes an instance method based on the class. The integer is then incremented and
      <code>
       goto
      </code>
      is called to loop back to instruction 2.
     </p>
     <p>
      This process continues until the
      <code>
       if_icmpge
      </code>
      comparison eventually succeeds (when the loop variable is &gt;= 10); on that iteration of the loop, control passes to instruction 22 and the method returns.
     </p>
    </div>
   </section>
   <section data-pdf-bookmark="Introducing HotSpot" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-2-SECT-4">
     <h1>
      Introducing HotSpot
     </h1>
     <p>
      In April 1999 Sun introduced one of the biggest changes to Java in terms of  performance.
      <a data-primary="HotSpot JVM" data-type="indexterm" id="idm139848329561040">
      </a>
      <a data-primary="JVMs (Java Virtual Machines)" data-secondary="overview" data-tertiary="HotSpot" data-type="indexterm" id="idm139848329560336">
      </a>
      The HotSpot virtual machine is a key feature of Java that has evolved to enable performance that is comparable to (or better than) languages such as C and
      <span class="keep-together">
       C++
      </span>
      (see
      <a data-type="xref" href="#pracjavaperf-CHP-2-FIG-3">
       Figure 2-3
      </a>
      ). To explain how this is possible, let’s delve a little deeper into the design of languages intended for application development.
     </p>
     <figure>
      <div class="figure" id="pracjavaperf-CHP-2-FIG-3">
       <img alt="opjv 0203" height="830" src="library/view/optimizing-java/9781492039259/assets/opjv_0203.png" width="1565"/>
       <h6>
        <span class="label">
         Figure 2-3.
        </span>
        The HotSpot JVM
       </h6>
      </div>
     </figure>
     <p>
      Language and platform design frequently involves making decisions and tradeoffs between desired capabilities.
      <a data-primary="programming languages, HotSpot and" data-type="indexterm" id="idm139848329554592">
      </a>
      In this case, the division is between languages that stay “close to the metal” and rely on ideas such as “zero-cost abstractions,” and languages that favor developer productivity and “getting things done” over strict low-level control.
      <a data-primary="zero-overhead principle" data-type="indexterm" id="idm139848329553472">
      </a>
     </p>
     <blockquote>
      <p>
       C++ implementations obey the zero-overhead principle: What you don’t use, you don’t pay for. And further: What you do use, you couldn’t hand code any better.
      </p>
      <p data-type="attribution">
       Bjarne Stroustrup
      </p>
     </blockquote>
     <p>
      The zero-overhead principle sounds great in theory, but it requires all users of the language to deal with the low-level reality of how operating systems and computers actually work. This is a significant extra cognitive burden that is placed upon developers who may not care about raw performance as a primary goal.
     </p>
     <p>
      Not only that, but it also requires the source code to be compiled to platform-specific machine code at build time—usually called
      <em>
       Ahead-of-Time
      </em>
      (AOT) compilation.
      <a data-primary="AOT (ahead-of-time) compilation" data-type="indexterm" id="idm139848329549344">
      </a>
      <a data-primary="ahead-of-time compilation" data-see="AOT compilation" data-type="indexterm" id="idm139848329548592">
      </a>
      This is because alternative execution models such as interpreters, virtual machines, and portablity layers all are most definitely not zero-overhead.
     </p>
     <p>
      The principle also hides a can of worms in the phrase “what you do use, you couldn’t hand code any better.”
This presupposes a number of things, not least that the developer is able to produce better code than an automated system.
This is not a safe assumption at all. Very few people want to code in assembly language anymore, so the use of automated systems (such as compilers) to produce code is clearly of some benefit to most programmers.
     </p>
     <p>
      Java has never subscribed to the zero-overhead abstraction philosophy.
Instead, the approach taken by the HotSpot virtual machine is to analyze the runtime behavior of your program and intelligently apply optimizations where they will benefit performance the most.
The goal of the HotSpot VM is to allow you to write idiomatic Java and follow good design principles rather then contort your program to fit the VM.
     </p>
     <section data-pdf-bookmark="Introducing Just-in-Time Compilation" data-type="sect2">
      <div class="sect2" id="pracjavaperf-CHP-2-SECT-4.1">
       <h2>
        Introducing Just-in-Time Compilation
       </h2>
       <p>
        Java programs begin their execution in the bytecode interpreter, where instructions are performed on a virtualized stack machine.
        <a data-primary="JIT (Just-in-Time) compilation" data-type="indexterm" id="idm139848329505536">
        </a>
        <a data-primary="HotSpot JVM" data-secondary="JIT compilation" data-type="indexterm" id="idm139848329504768">
        </a>
        This abstraction from the CPU gives the benefit of class file portability, but to get maximum performance your program must execute directly on the CPU, making use of its native features.
        <a data-primary="Just-in-Time compilation" data-see="JIT compilation" data-type="indexterm" id="idm139848329503488">
        </a>
       </p>
       <p>
        HotSpot achieves this by compiling units of your program from interpreted bytecode into native code.
The units of compilation in the HotSpot VM are the method and the loop. This is known as
        <em>
         Just-in-Time
        </em>
        (JIT) compilation.
       </p>
       <p>
        JIT compilation works by monitoring the application while it is running in interpreted mode and observing the parts of code that are most frequently executed.
During this analysis process, programmatic trace information is captured that allows for more sophisticated optimization.
Once execution of a particular method passes a threshold, the profiler will look to compile and optimize that particular section of code.
       </p>
       <p>
        There are many advantages to the JIT approach to compilation, but one of the main ones is that it bases compiler optimization decisions on trace information that is collected during the interpreted phase, enabling HotSpot to make more informed optimizations.
       </p>
       <p>
        Not only that, but HotSpot has had hundreds of engineering years (or more) of development attributed to it and new optimizations and benefits are added with almost every new release.
        <a data-primary="performance optimizations" data-secondary="in HotSpot VM" data-type="indexterm" id="idm139848329499344">
        </a>
        This means that any Java application that runs on top of a new release of HotSpot will be able to take advantage of new performance optimizations present in the VM, without even needing to be recompiled.
       </p>
       <div data-type="tip">
        <h6>
         Tip
        </h6>
        <p>
         After being translated from Java source to bytecode and now going through another step of (JIT) compilation, the code actually being executed has changed very significantly from the source code as written.
This is a key insight, and it will drive our approach to  dealing with performance-related investigations. JIT-compiled code executing on the JVM may well look nothing like the original Java source code.
        </p>
       </div>
       <p>
        The general picture is that languages like C++ (and the up-and-coming Rust) tend to have more predictable performance, but at the cost of forcing a lot of low-level complexity onto the user.
       </p>
       <p>
        Note that “more predictable” does not necessarily mean “better.”
AOT compilers produce code that may have to run across a broad class of processors, and may not be able to assume that specific processor features are available.
       </p>
       <p>
        Environments that use profile-guided optimization (PGO), such as Java, have the potential to use runtime information in ways that are simply impossible to most AOT platforms.
        <a data-primary="profile-guided optimization (PGO)" data-secondary="AOT platforms and" data-type="indexterm" id="idm139848329494560">
        </a>
        This can offer improvements to performance, such as dynamic inlining and optimizing away virtual calls.
HotSpot can even detect the precise CPU type it is running on at VM startup, and can use this information to enable optimizations designed for specific processor features if available.
        <a data-primary="processor capabilities, detection by JVM" data-type="indexterm" id="idm139848329493136">
        </a>
       </p>
       <div data-type="tip">
        <h6>
         Tip
        </h6>
        <p>
         The technique of detecting precise processor capabilities is known as
         <em>
          JVM intrinsics
         </em>
         , and is not to be confused with the intrinsic locks introduced by the
         <code>
          synchronized
         </code>
         keyword.
         <a data-primary="JVM intrinsics" data-see="intrinsics" data-type="indexterm" id="idm139848329490688">
         </a>
         <a data-primary="intrinsics" data-type="indexterm" id="idm139848329489680">
         </a>
        </p>
       </div>
       <p>
        A full discussion of PGO and JIT compilation can be found in Chapters
        <a href="ch09.html#pracjavaperf-CHP-9">
         9
        </a>
        and
        <a href="ch10.html#pracjavaperf-CHP-10">
         10
        </a>
        .
       </p>
       <p>
        The sophisticated approach that HotSpot takes is a great benefit to the majority of ordinary developers, but this tradeoff (to abandon zero-overhead abstractions) means that in the specific case of high-performance Java applications, the developer must be very careful to avoid “common sense” reasoning and overly simplistic mental models of how Java applications actually execute.
       </p>
       <div data-type="note" epub:type="note">
        <h6>
         Note
        </h6>
        <p>
         Analyzing the performance of small sections of Java code (
         <em>
          micro­benchmarks
         </em>
         ) is usually actually harder than analyzing entire applications, and is a very specialized task that the majority of developers should not undertake.
         <a data-primary="microbenchmarks" data-type="indexterm" id="idm139848329484656">
         </a>
         We will return to this subject in
         <a data-type="xref" href="ch05.html#pracjavaperf-CHP-5">
          Chapter 5
         </a>
         .
        </p>
       </div>
       <p>
        HotSpot’s compilation subsystem is one of the two most important subsystems that the virtual machine provides. The other is automatic memory management, which was one of the major selling points of Java in the early years.
       </p>
      </div>
     </section>
    </div>
   </section>
   <section data-pdf-bookmark="JVM Memory Management" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-2-SECT-5">
     <h1>
      JVM Memory Management
     </h1>
     <p>
      In languages such as C, C++, and Objective-C the programmer is responsible for managing the allocation and release of memory.
      <a data-primary="JVMs (Java Virtual Machines)" data-secondary="overview" data-tertiary="memory management" data-type="indexterm" id="idm139848329480400">
      </a>
      <a data-primary="memory management" data-secondary="by JVMs" data-type="indexterm" id="idm139848329479136">
      </a>
      The benefits of managing memory and lifetime of objects yourself are more deterministic performance and the ability to tie resource lifetime to the creation and deletion of objects. But these benefits come at a huge cost—for correctness, developers must be able to accurately account for memory.
     </p>
     <p>
      Unfortunately, decades of practical experience showed that many developers have a poor understanding of idioms and patterns for memory management. Later versions of C++ and Objective-C have improved this using smart pointer idioms in the standard library. However, at the time Java was created poor memory management was a major cause of application errors. This led to concern among developers and managers about the amount of time spent dealing with language features rather than delivering value for the business.
     </p>
     <p>
      Java looked to help resolve the problem by introducing automatically managed heap memory using a process known as
      <em>
       garbage collection
      </em>
      (GC).
      <a data-primary="garbage collection (GC)" data-type="indexterm" id="idm139848329475872">
      </a>
      Simply put, garbage collection is a nondeterministic process that triggers to recover and reuse no-longer-needed memory when the JVM requires more memory for allocation.
     </p>
     <p>
      However, the story behind GC is not quite so simple, and various algorithms for garbage collection have been developed and applied over the course of Java’s history. GC comes at a cost: when it runs, it often
      <em>
       stops the world
      </em>
      , which means while GC is in progress the application pauses. Usually these pause times are designed to be incredibly small, but as an application is put under pressure they can increase.
     </p>
     <p>
      Garbage collection is a major topic within Java performance optimization, so we will devote Chapters
      <a href="ch06.html#pracjavaperf-CHP-6">
       6
      </a>
      ,
      <a href="ch07.html#pracjavaperf-CHP-7">
       7
      </a>
      , and
      <a href="ch08.html#pracjavaperf-CHP-8">
       8
      </a>
      to the details of Java GC.
     </p>
    </div>
   </section>
   <section data-pdf-bookmark="Threading and the Java Memory Model" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-2-SECT-6">
     <h1>
      Threading and the Java Memory Model
     </h1>
     <p>
      One of the major advances that Java brought in with its first version was built-in support for multithreaded programming.
      <a data-primary="multithreading" data-seealso="threading; threads" data-type="indexterm" id="idm139848329468672">
      </a>
      <a data-primary="memory" data-secondary="threading and Java memory model" data-type="indexterm" id="idm139848329467696">
      </a>
      <a data-primary="JVMs (Java Virtual Machines)" data-secondary="overview" data-tertiary="threading and Java memory model" data-type="indexterm" id="idm139848329466688">
      </a>
      <a data-primary="threading" data-secondary="and the Java memory model" data-type="indexterm" id="idm139848329465440">
      </a>
      The Java platform allows the developer to create new threads of execution. For example, in Java 8 syntax:
     </p>
     <pre data-code-language="java" data-type="programlisting"><code class="n">Thread</code> <code class="n">t</code> <code class="o">=</code> <code class="k">new</code> <code class="n">Thread</code><code class="o">(()</code> <code class="o">-&gt;</code> <code class="o">{</code><code class="n">System</code><code class="o">.</code><code class="na">out</code><code class="o">.</code><code class="na">println</code><code class="o">(</code><code class="s">"Hello World!"</code><code class="o">);});</code>
<code class="n">t</code><code class="o">.</code><code class="na">start</code><code class="o">();</code></pre>
     <p>
      Not only that, but the Java environment is inherently multithreaded, as is the JVM.
This produces additional, irreducible complexity in the behavior of Java programs, and makes the work of the performance analyst even harder.
     </p>
     <p>
      In most mainstream JVM implementations, each Java application thread corresponds precisely to a dedicated operating system thread.
The alternative, using a shared pool of threads to execute all Java application threads (an approach known as
      <em>
       green threads
      </em>
      ), proved not to provide an acceptable performance profile and added needless complexity.
     </p>
     <div data-type="note" epub:type="note">
      <h6>
       Note
      </h6>
      <p>
       It is safe to assume that every JVM application thread is backed by a unique OS thread that is created when the
       <code>
        start()
       </code>
       method is called on the corresponding
       <code>
        Thread
       </code>
       object.
      </p>
     </div>
     <p>
      Java’s approach to multithreading dates
      <a data-primary="multithreading" data-secondary="Java's approach to" data-type="indexterm" id="idm139848329367408">
      </a>
      from the late 1990s and has these fundamental design principles:
     </p>
     <ul>
      <li>
       <p>
        All threads in a Java process share a single, common garbage-collected heap.
       </p>
      </li>
      <li>
       <p>
        Any object created by one thread can be accessed by any other thread that has a reference to the object.
       </p>
      </li>
      <li>
       <p>
        Objects are mutable by default; that is, the values held in object fields can be changed unless the programmer explicitly uses the
        <code>
         final
        </code>
        keyword to mark them as immutable.
       </p>
      </li>
     </ul>
     <p>
      The Java Memory Model (JMM) is
      <a data-primary="Java Memory Model (JMM)" data-type="indexterm" id="idm139848329362192">
      </a>
      a formal model of memory that explains how different threads of execution see the changing values held in objects.
      <a data-primary="JMM" data-see="Java Memory Model" data-type="indexterm" id="idm139848329361232">
      </a>
      That is, if threads A and B both have references to object
      <code>
       obj
      </code>
      , and thread A alters it, what happens to the value observed in thread B?
     </p>
     <p>
      This seemingly simple question is actually more complicated than it seems, because the operating system scheduler (which we will meet in
      <a data-type="xref" href="ch03.html#pracjavaperf-CHP-3">
       Chapter 3
      </a>
      ) can forcibly evict threads from CPU cores. This can lead to another thread starting to execute and accessing an object before the original thread had finished processing it, and potentially seeing the object in a damaged or invalid state.
     </p>
     <p>
      The only defense the core of Java provides against this potential object damage during
      <a data-primary="locks" data-type="indexterm" id="idm139848329357728">
      </a>
      concurrent code execution is the mutual exclusion lock, and this can be very complex to use in real applications.
      <a data-type="xref" href="ch12.html#pracjavaperf-CHP-12">
       Chapter 12
      </a>
      contains a detailed look at how the JMM works, and the practicalities of working with threads and locks.
     </p>
    </div>
   </section>
   <section data-pdf-bookmark="Meet the JVMs" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-2-SECT-7">
     <h1>
      Meet the JVMs
     </h1>
     <p>
      Many developers may only be immediately familiar with the Java implementation produced by Oracle.
      <a data-primary="JVMs (Java Virtual Machines)" data-secondary="overview" data-tertiary="JVM implementations" data-type="indexterm" id="idm139848329353904">
      </a>
      We have already met the virtual machine that comes from the Oracle implementation, HotSpot. However, there are several other implementations that we will discuss in this book, to varying degrees of depth:
     </p>
     <dl>
      <dt>
       OpenJDK
      </dt>
      <dd>
       <p>
        OpenJDK is an interesting special case.
        <a data-primary="OpenJDK" data-type="indexterm" id="idm139848329350432">
        </a>
        It is an open source (GPL) project that provides the reference implementation of Java. The project is led and supported by Oracle and provides the basis of its Java releases.
       </p>
      </dd>
      <dt>
       Oracle
      </dt>
      <dd>
       <p>
        Oracle’s Java is the most widely known implementation.
        <a data-primary="Oracle Java" data-type="indexterm" id="idm139848329348128">
        </a>
        It is based on OpenJDK, but relicensed under Oracle’s proprietary license. Almost all changes to Oracle Java start off as commits to an OpenJDK public repository (with the exception of security fixes that have not yet been publicly disclosed).
       </p>
      </dd>
      <dt>
       Zulu
      </dt>
      <dd>
       <p>
        Zulu is a free (GPL-licensed) OpenJDK implementation that is fully Java-certified and provided by Azul Systems.
        <a data-primary="Zulu" data-type="indexterm" id="idm139848329345632">
        </a>
        It is unencumbered by proprietary licenses and is freely redistributable. Azul is one of the few vendors to provide paid support for OpenJDK.
       </p>
      </dd>
      <dt>
       IcedTea
      </dt>
      <dd>
       <p>
        Red Hat was the first non-Oracle vendor to produce a fully certified Java implementation based on OpenJDK.
        <a data-primary="IcedTea" data-type="indexterm" id="idm139848329343232">
        </a>
        IcedTea is fully certified and redistributable.
       </p>
      </dd>
      <dt>
       Zing
      </dt>
      <dd>
       <p>
        Zing is a high-performance proprietary JVM.
        <a data-primary="Zing JVM" data-type="indexterm" id="idm139848329341120">
        </a>
        It is a fully certified implementation of Java and is produced by Azul Systems. It is 64-bit Linux only, and is designed for server-class systems with large heaps (10s of 100s of GB) and a lot of CPU.
       </p>
      </dd>
      <dt>
       J9
      </dt>
      <dd>
       <p>
        IBM’s J9 started life as a proprietary JVM but was open-sourced partway through its life (just like HotSpot).
        <a data-primary="J9 JVM" data-type="indexterm" id="idm139848329338656">
        </a>
        It is now built on top of an Eclipse open runtime project (OMR), and forms the basis of IBM’s proprietary product. It is fully compliant with Java certification.
       </p>
      </dd>
      <dt>
       Avian
      </dt>
      <dd>
       <p>
        The Avian implementation is not 100% Java conformant in terms of certification.
        <a data-primary="Avian JVM" data-type="indexterm" id="idm139848329457472">
        </a>
        It is included in this list because it is an interesting open source project and a great learning tool for developers interested in understanding the details of how a JVM works, rather than as a 100% production-ready solution.
       </p>
      </dd>
      <dt>
       Android
      </dt>
      <dd>
       <p>
        Google’s Android project is sometimes thought of as being “based on Java.” However,
        <a data-primary="Android" data-type="indexterm" id="idm139848329455008">
        </a>
        the picture is actually a little more complicated. Android originally used a different implementation of Java’s class libraries (from the clean-room Harmony project) and a cross compiler to convert to a different (
        <em>
         .dex
        </em>
        ) file format for a non-JVM virtual machine.
       </p>
      </dd>
     </dl>
     <p>
      Of these implementations, the great majority of the book focuses on HotSpot. This material applies equally to Oracle Java, Azul Zulu, Red Hat IcedTea, and all other OpenJDK-derived JVMs.
     </p>
     <div data-type="note" epub:type="note">
      <h6>
       Note
      </h6>
      <p>
       There are essentially no performance-related differences between the various HotSpot-based implementations, when comparing like-for-like versions.
      </p>
     </div>
     <p>
      We also include some material related to IBM J9 and Azul Zing. This is intended to provide an awareness of these alternatives rather than a definitive guide. Some readers may wish to explore these technologies more deeply, and they are encouraged to proceed by setting performance goals, and then measuring and comparing, in the usual manner.
     </p>
     <p>
      Android is moving to use the OpenJDK 8 class libraries with direct support in the Android runtime. As this technology stack is so far from the other examples, we won’t consider Android any further in this book.
     </p>
     <section data-pdf-bookmark="A Note on Licenses" data-type="sect2">
      <div class="sect2" id="pracjavaperf-CHP-2-SECT-7.1">
       <h2>
        A Note on Licenses
       </h2>
       <p>
        Almost all of the JVMs we will discuss are open source, and in fact, most of them are derived from the GPL-licensed HotSpot.
        <a data-primary="licenses for JVMs" data-type="indexterm" id="idm139848329448112">
        </a>
        The exceptions are IBM’s Open J9, which is Eclipse-licensed, and Azul Zing, which is commercial (although Azul’s Zulu product is GPL).
       </p>
       <p>
        The situation with Oracle Java (as of Java 9) is slightly more complex.
        <a data-primary="Oracle Java" data-secondary="licenses" data-type="indexterm" id="idm139848329446736">
        </a>
        Despite being derived from the OpenJDK code base, it is proprietary, and is
        <em>
         not
        </em>
        open source software.
Oracle achieves this by having all contributors to OpenJDK sign a license agreement that permits dual licensing of their contribution to both the GPL of OpenJDK and Oracle’s proprietary license.
       </p>
       <p>
        Each update release to Oracle Java is taken as a branch off the OpenJDK mainline, which is not then patched on-branch for future releases.
This prevents divergence of Oracle and OpenJDK, and accounts for the lack of meaningful difference between Oracle JDK and an OpenJDK binary based on the same source.
       </p>
       <p>
        This means that the only real difference between Oracle JDK and OpenJDK is the license. This may seem an irrelevance, but the Oracle license contains a few clauses that developers should be aware of:
       </p>
       <ul>
        <li>
         <p>
          Oracle does not grant the right to redistribute its binaries outside of your own organization (e.g., as a Docker image).
         </p>
        </li>
        <li>
         <p>
          You are not permitted to apply a binary patch to an Oracle binary without its agreement (which will usually mean a support contract).
         </p>
        </li>
       </ul>
       <p>
        There are also several other commercial features and tools that Oracle makes available that will only work with Oracle’s JDK, and within the terms of its license.
This situation will be changing with future releases of Java from Oracle, however, as we will discuss in
        <a data-type="xref" href="ch15.html#pracjavaperf-CHP-15">
         Chapter 15
        </a>
        .
       </p>
       <p>
        When planning a new greenfield deployment, developers and architects should consider carefully their choice of JVM vendor.
Some large organizations, notably Twitter and Alibaba, even maintain their own private builds of OpenJDK, although the engineering effort required for this is beyond the reach of many companies.
       </p>
      </div>
     </section>
    </div>
   </section>
   <section data-pdf-bookmark="Monitoring and Tooling for the JVM" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-2-SECT-8">
     <h1>
      Monitoring and Tooling for the JVM
     </h1>
     <p>
      The JVM is a mature execution platform, and it provides a number of technology alternatives for instrumentation, monitoring, and observability of running applications.
      <a data-primary="JVMs (Java Virtual Machines)" data-secondary="overview" data-tertiary="monitoring and tooling" data-type="indexterm" id="idm139848329436768">
      </a>
      The main technologies available for these types of tools for JVM applications are:
     </p>
     <ul>
      <li>
       <p>
        Java Management Extensions (JMX)
       </p>
      </li>
      <li>
       <p>
        Java agents
       </p>
      </li>
      <li>
       <p>
        The JVM Tool Interface (JVMTI)
       </p>
      </li>
      <li>
       <p>
        The Serviceability Agent (SA)
       </p>
      </li>
     </ul>
     <p>
      JMX is a powerful, general-purpose technology for controlling and monitoring JVMs and the applications running on them.
      <a data-primary="JMX (Java Management Extensions)" data-type="indexterm" id="idm139848329430784">
      </a>
      <a data-primary="Java Management Extensions" data-see="JMX" data-type="indexterm" id="idm139848329430016">
      </a>
      It provides the ability to change parameters and call methods in a general way from a client application.
A full treatment is, unfortunately, outside the scope of this book.
However, JMX (and its associated network transport, RMI) is a fundamental aspect of the management capabilities of the JVM.
     </p>
     <p>
      A Java agent is a tooling component, written in Java (hence the name), that makes use of the interfaces in
      <code>
       java.lang.instrument
      </code>
      to modify the bytecode of methods.
      <a data-primary="java.lang.instrument interfaces" data-type="indexterm" id="idm139848329427680">
      </a>
      <a data-primary="agents" data-type="indexterm" id="idm139848329426912">
      </a>
      <a data-primary="Java agents" data-see="agents" data-type="indexterm" id="idm139848329426240">
      </a>
      To install an agent, provide a startup flag to the JVM:
     </p>
     <pre data-type="programlisting">-javaagent:&lt;path-to-agent-jar&gt;=&lt;options&gt;</pre>
     <p>
      The agent JAR must contain a manifest and include the attribute
      <code>
       Premain-Class
      </code>
      .
This attribute contains the name of the agent class, which must implement a public static
      <code>
       premain()
      </code>
      method that acts as the registration hook for the Java agent.
     </p>
     <p>
      If the Java instrumentation API is not sufficient, then the JVMTI may be used instead.
      <a data-primary="JVM Tooling Interface (JVMTI)" data-type="indexterm" id="idm139848329422736">
      </a>
      This is a native interface of the JVM, so agents that make use of it must be written in a native compiled language—essentially, C or C++.
It can be thought of as a communication interface that allows a native agent to monitor and be informed of events by the JVM.
To install a native agent, provide a slightly different flag:
     </p>
     <pre data-type="programlisting">-agentlib:&lt;agent-lib-name&gt;=&lt;options&gt;</pre>
     <p class="pagebreak-before">
      or:
     </p>
     <pre data-type="programlisting">-agentpath:&lt;path-to-agent&gt;=&lt;options&gt;</pre>
     <p>
      The requirement that JVMTI agents be written in native code means that it is much easier to write code that can damage running applications and even crash the JVM.
     </p>
     <p>
      Where possible, it is usually preferable to write a Java agent over JVMTI code.
Agents are much easier to write, but some information is not available through the Java API, and to access that data JVMTI may be the only possibility available.
     </p>
     <p>
      The final approach is the Serviceability Agent.
      <a data-primary="Serviceability Agent (SA)" data-type="indexterm" id="idm139848329417680">
      </a>
      This is a set of APIs and tools that can expose both Java objects and HotSpot data structures.
     </p>
     <p>
      The SA does not require any code to be run in the target VM.
Instead, the HotSpot SA uses primitives like symbol lookup and reading of process memory to implement debugging capability.
The SA has the ability to debug live Java processes as well as core files (also called
      <em>
       crash dump files
      </em>
      ).
     </p>
     <section data-pdf-bookmark="VisualVM" data-type="sect2">
      <div class="sect2" id="pracjavaperf-CHP-2-SECT-8.1">
       <h2>
        VisualVM
       </h2>
       <p>
        The JDK ships with a number of useful additional tools along with the well-known binaries such as
        <code>
         javac
        </code>
        and
        <code>
         java
        </code>
        .
One tool that is often overlooked is VisualVM, which is a graphical tool based on the NetBeans platform.
        <a data-primary="VisualVM" data-type="indexterm" id="idm139848329412304">
        </a>
       </p>
       <div data-type="tip">
        <h6>
         Tip
        </h6>
        <p>
         <code>
          jvisualvm
         </code>
         is a replacement for the now obsolete
         <code>
          jconsole
         </code>
         tool from earlier Java versions.
If you are still using
         <code>
          jconsole
         </code>
         , you should move to VisualVM (there is a compatibility plug-in to allow
         <code>
          jconsole
         </code>
         plug-ins to run inside VisualVM).
        </p>
       </div>
       <p>
        Recent versions of Java have shipped solid versions of VisualVM, and the version present in the JDK is now usually sufficient.
However, if you need to use a more recent version, you can download the latest version from
        <a href="http://visualvm.java.net/">
         <em class="hyperlink">
          http://visualvm.java.net/
         </em>
        </a>
        .
After downloading, you will have to ensure that the
        <code>
         visualvm
        </code>
        binary is added to your path or you’ll get the JRE default binary.
       </p>
       <div data-type="tip">
        <h6>
         Tip
        </h6>
        <p>
         From Java 9 onward, VisualVM is being removed from the main distribution, so developers will have to download the binary separately.
        </p>
       </div>
       <p>
        When VisualVM is started for the first time it will calibrate the machine it is running on, so there should be no other applications running that might affect the performance calibration.
After calibration, VisualVM will finish starting up and show a splash screen.
The most familiar view of VisualVM is the Monitor screen, which is similar to that shown in
        <a data-type="xref" href="#pracjavaperf-CHP-2-FIG-4">
         Figure 2-4
        </a>
        .
       </p>
       <figure>
        <div class="figure" id="pracjavaperf-CHP-2-FIG-4">
         <img alt="opjv 0204" height="929" src="library/view/optimizing-java/9781492039259/assets/opjv_0204.png" width="1440"/>
         <h6>
          <span class="label">
           Figure 2-4.
          </span>
          VisualVM Monitor screen
         </h6>
        </div>
       </figure>
       <p>
        VisualVM is used for live monitoring of a running process, and it uses the JVM’s
        <em>
         attach mechanism
        </em>
        .
This works slightly differently depending on whether the process is local or remote.
       </p>
       <p>
        Local processes are fairly straightforward.
VisualVM lists them down the lefthand side of the screen. Double-clicking on one of them causes it to appear as a new tab in the righthand pane.
       </p>
       <p>
        To connect to a remote process, the remote side must accept inbound connections (over JMX).
        <a data-primary="jstatd" data-type="indexterm" id="idm139848329308752">
        </a>
        For standard Java processes, this means
        <code>
         jstatd
        </code>
        must be running on the remote host (see the manual page  for
        <code>
         jstatd
        </code>
        for more details).
       </p>
       <div data-type="note" epub:type="note">
        <h6>
         Note
        </h6>
        <p>
         Many application servers and execution containers provide an equivalent capability to
         <code>
          jstatd
         </code>
         directly in the server. Such processes do not need a separate
         <code>
          jstatd
         </code>
         process.
        </p>
       </div>
       <p>
        To connect to a remote process, enter the hostname and a display name that will be used on the tab. The default port to connect to is 1099, but this can be changed easily.
       </p>
       <p class="pagebreak-before">
        Out of the box,
        <a data-primary="VisualVM" data-secondary="Overview, Monitor, Threads, Sampler, and Profiler tabs" data-type="indexterm" id="idm139848329303728">
        </a>
        VisualVM presents the user with five tabs:
       </p>
       <dl>
        <dt>
         Overview
        </dt>
        <dd>
         <p>
          Provides a summary of information about your Java process.
          <a data-primary="Overview tab (VisualVM)" data-type="indexterm" id="idm139848329300800">
          </a>
          This includes the full flags that were passed in and all system properties. It also displays the exact Java version executing.
         </p>
        </dd>
        <dt>
         Monitor
        </dt>
        <dd>
         <p>
          This is the tab that is the most similar to the legacy JConsole view.
          <a data-primary="Monitor tab (VisualVM)" data-type="indexterm" id="idm139848329298544">
          </a>
          It shows high-level telemetry for the JVM, including CPU and heap usage. It also shows the number of classes loaded and unloaded, and an overview of the numbers of threads running.
         </p>
        </dd>
        <dt>
         Threads
        </dt>
        <dd>
         <p>
          Each thread in the running application is displayed with a timeline.
          <a data-primary="Threads tab (VisualVM)" data-type="indexterm" id="idm139848329296240">
          </a>
          This includes both application threads and VM threads. The state of each thread can be seen, with a small amount of history. Thread dumps can also be generated if needed.
         </p>
        </dd>
        <dt>
         Sampler and Profiler
        </dt>
        <dd>
         <p>
          In these views,
          <a data-primary="Sampler tab (VisualVM)" data-type="indexterm" id="idm139848329293936">
          </a>
          <a data-primary="Profiler tab (VisualVM)" data-type="indexterm" id="idm139848329293200">
          </a>
          simplified sampling of CPU and memory utilization can be accessed. This will be discussed more fully in
          <a data-type="xref" href="ch13.html#pracjavaperf-CHP-13">
           Chapter 13
          </a>
          .
         </p>
        </dd>
       </dl>
       <p>
        The plug-in architecture of VisualVM allows additional tools to be easily added to the core platform to augment the core functionality.
These include plug-ins that allow interaction with JMX consoles and bridging to legacy JConsole, and a very useful garbage collection plug-in, VisualGC.
       </p>
      </div>
     </section>
    </div>
   </section>
   <section data-pdf-bookmark="Summary" data-type="sect1">
    <div class="sect1" id="pracjavaperf-CHP-2-SECT-9">
     <h1>
      Summary
     </h1>
     <p>
      In this chapter we have taken a quick tour through the overall anatomy of the JVM.
It has only been possible to touch on some of the most important subjects, and virtually every topic mentioned here has a rich, full story behind it that will reward further investigation.
     </p>
     <p>
      In
      <a data-type="xref" href="ch03.html#pracjavaperf-CHP-3">
       Chapter 3
      </a>
      we will discuss some details of how operating systems and hardware work. This is to provide necessary background for the Java performance analyst to understand observed results. We will also look at the timing subsystem in more detail, as a complete example of how the VM and native subsystems interact.
      <a data-primary="JVMs (Java Virtual Machines)" data-secondary="overview" data-startref="ix_JVMovr" data-type="indexterm" id="idm139848329287264">
      </a>
      <a data-primary="performance" data-secondary="understanding the JVM" data-startref="ix_perfundJVM" data-type="indexterm" id="idm139848329286032">
      </a>
     </p>
    </div>
   </section>
  </div>
 </section>
</div>
</div>
</body>
</html>
